<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Ax · Adaptive Experimentation Platform</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Adaptive Experimentation Platform"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Ax · Adaptive Experimentation Platform"/><meta property="og:type" content="website"/><meta property="og:url" content="https://ax.dev//versions/latest/index.html"/><meta property="og:description" content="Adaptive Experimentation Platform"/><meta property="og:image" content="https://ax.dev//versions/latest/img/ax.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://ax.dev//versions/latest/img/ax.svg"/><link rel="shortcut icon" href="/versions/latest/img/favicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-139570076-1', 'auto');
              ga('send', 'pageview');
            </script><script type="text/javascript" src="https://cdn.plot.ly/plotly-latest.min.js"></script><script type="text/javascript" src="/versions/latest/js/plotUtils.js"></script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/versions/latest/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/versions/latest/js/scrollSpy.js"></script><link rel="stylesheet" href="/versions/latest/css/main.css"/><script src="/versions/latest/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/versions/latest/"><img class="logo" src="/versions/latest/img/ax_lockup_white.svg" alt="Ax"/><h2 class="headerTitleWithLogo">Ax</h2></a><a href="/versions/latest/versions.html"><h3>latest</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/versions/latest/docs/why-ax.html" target="_self">Docs</a></li><li class=""><a href="/versions/latest/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/versions/latest/api/" target="_self">API</a></li><li class=""><a href="https://github.com/facebook/Ax" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./"
src="/js/documentation_options.js">
</script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<div class="section" id="module-ax.models">
<span id="ax-models"></span><h1>ax.models<a class="headerlink" href="#module-ax.models" title="Permalink to this headline">¶</a></h1>
<div class="section" id="base-models">
<h2>Base Models<a class="headerlink" href="#base-models" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-ax.models.base">
<span id="ax-models-base"></span><h3>ax.models.base<a class="headerlink" href="#module-ax.models.base" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.base.Model">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.base.</code><code class="sig-name descname">Model</code><a class="reference internal" href="_modules/ax/models/base.html#Model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.base.Model" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Base class for an Ax model.</p>
<p>Note: the core methods each model has: <cite>fit</cite>, <cite>predict</cite>, <cite>gen</cite>,
<cite>cross_validate</cite>, and <cite>best_point</cite> are not present in this base class,
because the signatures for those methods vary based on the type of the model.
This class only contains the methods that all models have in common and for
which they all share the signature.</p>
<dl class="method">
<dt id="ax.models.base.Model.deserialize_state">
<em class="property">classmethod </em><code class="sig-name descname">deserialize_state</code><span class="sig-paren">(</span><em class="sig-param">serialized_state: Dict[str, Any]</em><span class="sig-paren">)</span> → Dict[str, Any]<a class="reference internal" href="_modules/ax/models/base.html#Model.deserialize_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.base.Model.deserialize_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Restores model’s state from its serialized form, to the format it
expects to receive as kwargs.</p>
</dd></dl>
<dl class="method">
<dt id="ax.models.base.Model.feature_importances">
<code class="sig-name descname">feature_importances</code><span class="sig-paren">(</span><span class="sig-paren">)</span> → Any<a class="reference internal" href="_modules/ax/models/base.html#Model.feature_importances"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.base.Model.feature_importances" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.base.Model.serialize_state">
<em class="property">classmethod </em><code class="sig-name descname">serialize_state</code><span class="sig-paren">(</span><em class="sig-param">raw_state: Dict[str, Any]</em><span class="sig-paren">)</span> → Dict[str, Any]<a class="reference internal" href="_modules/ax/models/base.html#Model.serialize_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.base.Model.serialize_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Serialized output of <cite>self._get_state</cite> to a JSON-ready dict.
This may involve storing part of state in files / external storage and
saving handles for that storage in the resulting serialized state.</p>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.discrete_base">
<span id="ax-models-discrete-base-module"></span><h3>ax.models.discrete_base module<a class="headerlink" href="#module-ax.models.discrete_base" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.discrete_base.DiscreteModel">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.discrete_base.</code><code class="sig-name descname">DiscreteModel</code><a class="reference internal" href="_modules/ax/models/discrete_base.html#DiscreteModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete_base.DiscreteModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.base.Model" title="ax.models.base.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.base.Model</span></code></a></p>
<p>This class specifies the interface for a model based on discrete parameters.</p>
<p>These methods should be implemented to have access to all of the features
of Ax.</p>
<dl class="method">
<dt id="ax.models.discrete_base.DiscreteModel.best_point">
<code class="sig-name descname">best_point</code><span class="sig-paren">(</span><em class="sig-param">n: int, parameter_values: List[List[Union[str, bool, float, int, None]]], objective_weights: Optional[numpy.ndarray], outcome_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, fixed_features: Optional[Dict[int, Union[str, bool, float, int, None]]] = None, pending_observations: Optional[List[List[List[Union[str, bool, float, int, None]]]]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None</em><span class="sig-paren">)</span> → Optional[List[Union[str, bool, float, int, None]]]<a class="reference internal" href="_modules/ax/models/discrete_base.html#DiscreteModel.best_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete_base.DiscreteModel.best_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtains the point that has the best value according to the model
prediction and its model predictions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(1 x d) parameter value list representing the point with the best
value according to the model prediction. None if this function
is not implemented for the given model.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.discrete_base.DiscreteModel.cross_validate">
<code class="sig-name descname">cross_validate</code><span class="sig-paren">(</span><em class="sig-param">Xs_train: List[List[List[Union[str, bool, float, int, None]]]], Ys_train: List[List[float]], Yvars_train: List[List[float]], X_test: List[List[Union[str, bool, float, int, None]]]</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/discrete_base.html#DiscreteModel.cross_validate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete_base.DiscreteModel.cross_validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Do cross validation with the given training and test sets.</p>
<p>Training set is given in the same format as to fit. Test set is given
in the same format as to predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs_train</strong> – A list of m lists X of parameterizations (each parameterization
is a list of parameter values of length d), each of length k_i,
for each outcome.</p></li>
<li><p><strong>Ys_train</strong> – The corresponding list of m lists Y, each of length k_i, for
each outcome.</p></li>
<li><p><strong>Yvars_train</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>X_test</strong> – List of the j parameterizations at which to make predictions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) array of outcome predictions at X.</p></li>
<li><p>(j x m x m) array of predictive covariances at X.
<cite>cov[j, m1, m2]</cite> is <cite>Cov[m1@j, m2@j]</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.discrete_base.DiscreteModel.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[List[List[Union[str, bool, float, int, None]]]], Ys: List[List[float]], Yvars: List[List[float]], parameter_values: List[List[Union[str, bool, float, int, None]]], outcome_names: List[str]</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/discrete_base.html#DiscreteModel.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete_base.DiscreteModel.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to m outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – A list of m lists X of parameterizations (each parameterization
is a list of parameter values of length d), each of length k_i,
for each outcome.</p></li>
<li><p><strong>Ys</strong> – The corresponding list of m lists Y, each of length k_i, for
each outcome.</p></li>
<li><p><strong>Yvars</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>parameter_values</strong> – A list of possible values for each parameter.</p></li>
<li><p><strong>outcome_names</strong> – A list of m outcome names.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.discrete_base.DiscreteModel.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, parameter_values: List[List[Union[str, bool, float, int, None]]], objective_weights: Optional[numpy.ndarray], outcome_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, fixed_features: Optional[Dict[int, Union[str, bool, float, int, None]]] = None, pending_observations: Optional[List[List[List[Union[str, bool, float, int, None]]]]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None</em><span class="sig-paren">)</span> → Tuple[List[List[Union[str, bool, float, int, None]]], List[float], Dict[str, Any]]<a class="reference internal" href="_modules/ax/models/discrete_base.html#DiscreteModel.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete_base.DiscreteModel.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>parameter_values</strong> – A list of possible values for each parameter.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>pending_observations</strong> – A list of m lists of parameterizations
(each parameterization is a list of parameter values of length d),
each of length k_i, for each outcome i.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>List of n generated points, where each point is represented
by a list of parameter values.</p></li>
<li><p>List of weights for each of the n points.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.discrete_base.DiscreteModel.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X: List[List[Union[str, bool, float, int, None]]]</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/discrete_base.html#DiscreteModel.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete_base.DiscreteModel.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – List of the j parameterizations at which to make predictions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) array of outcome predictions at X.</p></li>
<li><p>(j x m x m) array of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.model_utils">
<span id="ax-models-model-utils-module"></span><h3>ax.models.model_utils module<a class="headerlink" href="#module-ax.models.model_utils" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="ax.models.model_utils.add_fixed_features">
<code class="sig-prename descclassname">ax.models.model_utils.</code><code class="sig-name descname">add_fixed_features</code><span class="sig-paren">(</span><em class="sig-param">tunable_points: numpy.ndarray, d: int, fixed_features: Optional[Dict[int, float]], tunable_feature_indices: numpy.ndarray</em><span class="sig-paren">)</span> → numpy.ndarray<a class="reference internal" href="_modules/ax/models/model_utils.html#add_fixed_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.model_utils.add_fixed_features" title="Permalink to this definition">¶</a></dt>
<dd><p>Add fixed features to points in tunable space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tunable_points</strong> – Points in tunable space.</p></li>
<li><p><strong>d</strong> – Dimension of parameter space.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>tunable_feature_indices</strong> – Parameter indices (in d) which are tunable.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Points in the full d-dimensional space, defined by bounds.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>points</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.model_utils.as_array">
<code class="sig-prename descclassname">ax.models.model_utils.</code><code class="sig-name descname">as_array</code><span class="sig-paren">(</span><em class="sig-param">x: Union[torch.Tensor, numpy.ndarray, Tuple[Union[torch.Tensor, numpy.ndarray], ...]]</em><span class="sig-paren">)</span> → Union[numpy.ndarray, Tuple[numpy.ndarray, ...]]<a class="reference internal" href="_modules/ax/models/model_utils.html#as_array"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.model_utils.as_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert every item in a tuple of tensors/arrays into an array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> – A tensor, array, or a tuple of potentially mixed tensors and arrays.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>x, with everything converted to array.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.model_utils.best_in_sample_point">
<code class="sig-prename descclassname">ax.models.model_utils.</code><code class="sig-name descname">best_in_sample_point</code><span class="sig-paren">(</span><em class="sig-param">Xs: Union[List[torch.Tensor], List[numpy.ndarray]], model: Union[ax.models.numpy_base.NumpyModel, ax.models.torch_base.TorchModel], bounds: List[Tuple[float, float]], objective_weights: Union[torch.Tensor, numpy.ndarray, None], outcome_constraints: Optional[Tuple[Union[torch.Tensor, numpy.ndarray], Union[torch.Tensor, numpy.ndarray]]] = None, linear_constraints: Optional[Tuple[Union[torch.Tensor, numpy.ndarray], Union[torch.Tensor, numpy.ndarray]]] = None, fixed_features: Optional[Dict[int, float]] = None, options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None</em><span class="sig-paren">)</span> → Optional[Tuple[Union[torch.Tensor, numpy.ndarray], float]]<a class="reference internal" href="_modules/ax/models/model_utils.html#best_in_sample_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.model_utils.best_in_sample_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Select the best point that has been observed.</p>
<p>Implements two approaches to selecting the best point.</p>
<p>For both approaches, only points that satisfy parameter space constraints
(bounds, linear_constraints, fixed_features) will be returned. Points must
also be observed for all objective and constraint outcomes. Returned
points may violate outcome constraints, depending on the method below.</p>
<p>1: Select the point that maximizes the expected utility
(objective_weights^T posterior_objective_means - baseline) * Prob(feasible)
Here baseline should be selected so that at least one point has positive
utility. It can be specified in the options dict, otherwise
min (objective_weights^T posterior_objective_means)
will be used, where the min is over observed points.</p>
<p>2: Select the best-objective point that is feasible with at least
probability p.</p>
<p>The following quantities may be specified in the options dict:</p>
<ul class="simple">
<li><p>best_point_method: ‘max_utility’ (default) or ‘feasible_threshold’
to select between the two approaches described above.</p></li>
<li><p>utility_baseline: Value for the baseline used in max_utility approach. If
not provided, defaults to min objective value.</p></li>
<li><p>probability_threshold: Threshold for the feasible_threshold approach.
Defaults to p=0.95.</p></li>
<li><p>feasibility_mc_samples: Number of MC samples used for estimating the
probability of feasibility (defaults 10k).</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – Training data for the points, among which to select the best.</p></li>
<li><p><strong>model</strong> – Numpy or Torch model.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each feature.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value in the best point.</p></li>
<li><p><strong>options</strong> – A config dictionary with settings described above.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>d-array of the best point,</p></li>
<li><p>utility at the best point.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-element tuple or None if no feasible point exist. In tuple</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.model_utils.best_observed_point">
<code class="sig-prename descclassname">ax.models.model_utils.</code><code class="sig-name descname">best_observed_point</code><span class="sig-paren">(</span><em class="sig-param">model: Union[ax.models.numpy_base.NumpyModel, ax.models.torch_base.TorchModel], bounds: List[Tuple[float, float]], objective_weights: Union[torch.Tensor, numpy.ndarray, None], outcome_constraints: Optional[Tuple[Union[torch.Tensor, numpy.ndarray], Union[torch.Tensor, numpy.ndarray]]] = None, linear_constraints: Optional[Tuple[Union[torch.Tensor, numpy.ndarray], Union[torch.Tensor, numpy.ndarray]]] = None, fixed_features: Optional[Dict[int, float]] = None, options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None</em><span class="sig-paren">)</span> → Union[torch.Tensor, numpy.ndarray, None]<a class="reference internal" href="_modules/ax/models/model_utils.html#best_observed_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.model_utils.best_observed_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Select the best point that has been observed.</p>
<p>Implements two approaches to selecting the best point.</p>
<p>For both approaches, only points that satisfy parameter space constraints
(bounds, linear_constraints, fixed_features) will be returned. Points must
also be observed for all objective and constraint outcomes. Returned
points may violate outcome constraints, depending on the method below.</p>
<p>1: Select the point that maximizes the expected utility
(objective_weights^T posterior_objective_means - baseline) * Prob(feasible)
Here baseline should be selected so that at least one point has positive
utility. It can be specified in the options dict, otherwise
min (objective_weights^T posterior_objective_means)
will be used, where the min is over observed points.</p>
<p>2: Select the best-objective point that is feasible with at least
probability p.</p>
<p>The following quantities may be specified in the options dict:</p>
<ul class="simple">
<li><p>best_point_method: ‘max_utility’ (default) or ‘feasible_threshold’
to select between the two approaches described above.</p></li>
<li><p>utility_baseline: Value for the baseline used in max_utility approach. If
not provided, defaults to min objective value.</p></li>
<li><p>probability_threshold: Threshold for the feasible_threshold approach.
Defaults to p=0.95.</p></li>
<li><p>feasibility_mc_samples: Number of MC samples used for estimating the
probability of feasibility (defaults 10k).</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Numpy or Torch model.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each feature.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value in the best point.</p></li>
<li><p><strong>options</strong> – A config dictionary with settings described above.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A d-array of the best point, or None if no feasible point exists.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.model_utils.check_duplicate">
<code class="sig-prename descclassname">ax.models.model_utils.</code><code class="sig-name descname">check_duplicate</code><span class="sig-paren">(</span><em class="sig-param">point: numpy.ndarray</em>, <em class="sig-param">points: numpy.ndarray</em><span class="sig-paren">)</span> → bool<a class="reference internal" href="_modules/ax/models/model_utils.html#check_duplicate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.model_utils.check_duplicate" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if a point exists in another array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>point</strong> – Newly generated point to check.</p></li>
<li><p><strong>points</strong> – Points previously generated.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True if the point is contained in points, else False</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.model_utils.check_param_constraints">
<code class="sig-prename descclassname">ax.models.model_utils.</code><code class="sig-name descname">check_param_constraints</code><span class="sig-paren">(</span><em class="sig-param">linear_constraints: Tuple[numpy.ndarray, numpy.ndarray], point: numpy.ndarray</em><span class="sig-paren">)</span> → Tuple[bool, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/model_utils.html#check_param_constraints"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.model_utils.check_param_constraints" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if a point satisfies parameter constraints.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>point</strong> – A candidate point in d-dimensional space, as a (1 x d) matrix.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>Flag that is True if all constraints are satisfied by the point.</p></li>
<li><p>Indices of constraints which are violated by the point.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.model_utils.filter_constraints_and_fixed_features">
<code class="sig-prename descclassname">ax.models.model_utils.</code><code class="sig-name descname">filter_constraints_and_fixed_features</code><span class="sig-paren">(</span><em class="sig-param">X: Union[torch.Tensor, numpy.ndarray], bounds: List[Tuple[float, float]], linear_constraints: Optional[Tuple[Union[torch.Tensor, numpy.ndarray], Union[torch.Tensor, numpy.ndarray]]] = None, fixed_features: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Union[torch.Tensor, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/model_utils.html#filter_constraints_and_fixed_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.model_utils.filter_constraints_and_fixed_features" title="Permalink to this definition">¶</a></dt>
<dd><p>Filter points to those that satisfy bounds, linear_constraints, and
fixed_features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – An tensor or array of points.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each feature.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value in the best point.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Feasible points.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.model_utils.get_observed">
<code class="sig-prename descclassname">ax.models.model_utils.</code><code class="sig-name descname">get_observed</code><span class="sig-paren">(</span><em class="sig-param">Xs: Union[List[torch.Tensor], List[numpy.ndarray]], objective_weights: Union[torch.Tensor, numpy.ndarray], outcome_constraints: Optional[Tuple[Union[torch.Tensor, numpy.ndarray], Union[torch.Tensor, numpy.ndarray]]] = None</em><span class="sig-paren">)</span> → Union[torch.Tensor, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/model_utils.html#get_observed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.model_utils.get_observed" title="Permalink to this definition">¶</a></dt>
<dd><p>Filter points to those that are observed for objective outcomes and outcomes
that show up in outcome_constraints (if there are any).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – A list of m (k_i x d) feature matrices X. Number of rows k_i
can vary from i=1,…,m.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Points observed for all objective outcomes and outcome constraints.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.model_utils.rejection_sample">
<code class="sig-prename descclassname">ax.models.model_utils.</code><code class="sig-name descname">rejection_sample</code><span class="sig-paren">(</span><em class="sig-param">gen_unconstrained: Callable[[int, int, numpy.ndarray, Optional[Dict[int, float]]], numpy.ndarray], n: int, d: int, tunable_feature_indices: numpy.ndarray, linear_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, deduplicate: bool = False, max_draws: Optional[int] = None, fixed_features: Optional[Dict[int, float]] = None, rounding_func: Optional[Callable[[numpy.ndarray], numpy.ndarray]] = None, existing_points: Optional[numpy.ndarray] = None</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, int]<a class="reference internal" href="_modules/ax/models/model_utils.html#rejection_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.model_utils.rejection_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Rejection sample in parameter space.</p>
<p>Models must implement a <cite>gen_unconstrained</cite> method in order to support
rejection sampling via this utility.</p>
</dd></dl>
<dl class="function">
<dt id="ax.models.model_utils.tunable_feature_indices">
<code class="sig-prename descclassname">ax.models.model_utils.</code><code class="sig-name descname">tunable_feature_indices</code><span class="sig-paren">(</span><em class="sig-param">bounds: List[Tuple[float, float]], fixed_features: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → numpy.ndarray<a class="reference internal" href="_modules/ax/models/model_utils.html#tunable_feature_indices"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.model_utils.tunable_feature_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the feature indices of tunable features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The indices of tunable features.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.model_utils.validate_bounds">
<code class="sig-prename descclassname">ax.models.model_utils.</code><code class="sig-name descname">validate_bounds</code><span class="sig-paren">(</span><em class="sig-param">bounds: List[Tuple[float, float]], fixed_feature_indices: numpy.ndarray</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/model_utils.html#validate_bounds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.model_utils.validate_bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>Ensure the requested space is [0,1]^d.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bounds</strong> – A list of d (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>fixed_feature_indices</strong> – Indices of features which are fixed at a
particular value.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.numpy_base">
<span id="ax-models-numpy-base-module"></span><h3>ax.models.numpy_base module<a class="headerlink" href="#module-ax.models.numpy_base" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.numpy_base.NumpyModel">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.numpy_base.</code><code class="sig-name descname">NumpyModel</code><a class="reference internal" href="_modules/ax/models/numpy_base.html#NumpyModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.numpy_base.NumpyModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.base.Model" title="ax.models.base.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.base.Model</span></code></a></p>
<p>This class specifies the interface for a numpy-based model.</p>
<p>These methods should be implemented to have access to all of the features
of Ax.</p>
<dl class="method">
<dt id="ax.models.numpy_base.NumpyModel.best_point">
<code class="sig-name descname">best_point</code><span class="sig-paren">(</span><em class="sig-param">bounds: List[Tuple[float, float]], objective_weights: numpy.ndarray, outcome_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, linear_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None</em><span class="sig-paren">)</span> → Optional[numpy.ndarray]<a class="reference internal" href="_modules/ax/models/numpy_base.html#NumpyModel.best_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.numpy_base.NumpyModel.best_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Identify the current best point, satisfying the constraints in the same
format as to gen.</p>
<p>Return None if no such point can be identified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value in the best point.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A d-array of the best point.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.numpy_base.NumpyModel.cross_validate">
<code class="sig-name descname">cross_validate</code><span class="sig-paren">(</span><em class="sig-param">Xs_train: List[numpy.ndarray], Ys_train: List[numpy.ndarray], Yvars_train: List[numpy.ndarray], X_test: numpy.ndarray</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/numpy_base.html#NumpyModel.cross_validate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.numpy_base.NumpyModel.cross_validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Do cross validation with the given training and test sets.</p>
<p>Training set is given in the same format as to fit. Test set is given
in the same format as to predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs_train</strong> – A list of m (k_i x d) feature matrices X. Number of rows
k_i can vary from i=1,…,m.</p></li>
<li><p><strong>Ys_train</strong> – The corresponding list of m (k_i x 1) outcome arrays Y,
for each outcome.</p></li>
<li><p><strong>Yvars_train</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>X_test</strong> – (j x d) array of the j points at which to make predictions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) array of outcome predictions at X.</p></li>
<li><p>(j x m x m) array of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.numpy_base.NumpyModel.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[numpy.ndarray], Ys: List[numpy.ndarray], Yvars: List[numpy.ndarray], bounds: List[Tuple[float, float]], task_features: List[int], feature_names: List[str], metric_names: List[str], fidelity_features: List[int], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/numpy_base.html#NumpyModel.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.numpy_base.NumpyModel.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to m outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – A list of m (k_i x d) feature matrices X. Number of rows k_i
can vary from i=1,…,m.</p></li>
<li><p><strong>Ys</strong> – The corresponding list of m (k_i x 1) outcome arrays Y, for
each outcome.</p></li>
<li><p><strong>Yvars</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>bounds</strong> – A list of d (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>task_features</strong> – Columns of X that take integer values and should be
treated as task parameters.</p></li>
<li><p><strong>feature_names</strong> – Names of each column of X.</p></li>
<li><p><strong>metric_names</strong> – Names of each outcome Y in Ys.</p></li>
<li><p><strong>fidelity_features</strong> – Columns of X that should be treated as fidelity
parameters.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.numpy_base.NumpyModel.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List[Tuple[float, float]], objective_weights: numpy.ndarray, outcome_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, linear_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, fixed_features: Optional[Dict[int, float]] = None, pending_observations: Optional[List[numpy.ndarray]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[numpy.ndarray], numpy.ndarray]] = None</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, numpy.ndarray, Dict[str, Any], Optional[List[Optional[Dict[str, Any]]]]]<a class="reference internal" href="_modules/ax/models/numpy_base.html#NumpyModel.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.numpy_base.NumpyModel.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>pending_observations</strong> – A list of m (k_i x d) feature arrays X
for m outcomes and k_i pending observations for outcome i.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result (xbest)
appropriately (i.e., according to <cite>round-trip</cite> transformations)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>4-element tuple containing</p>
<ul class="simple">
<li><p>(n x d) tensor of generated points.</p></li>
<li><p>n-tensor of weights for each point.</p></li>
<li><p>Generation metadata</p></li>
<li><dl class="simple">
<dt>Dictionary of model-specific metadata for the given</dt><dd><p>generation candidates</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.numpy_base.NumpyModel.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X: numpy.ndarray</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/numpy_base.html#NumpyModel.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.numpy_base.NumpyModel.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – (j x d) array of the j points at which to make predictions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) array of outcome predictions at X.</p></li>
<li><p>(j x m x m) array of predictive covariances at X.
<cite>cov[j, m1, m2]</cite> is <cite>Cov[m1@j, m2@j]</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.numpy_base.NumpyModel.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[numpy.ndarray], Ys: List[numpy.ndarray], Yvars: List[numpy.ndarray], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/numpy_base.html#NumpyModel.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.numpy_base.NumpyModel.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the model.</p>
<p>Updating the model requires both existing and additional data.
The data passed into this method will become the new training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>Ys</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>Yvars</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch_base">
<span id="ax-models-torch-base-module"></span><h3>ax.models.torch_base module<a class="headerlink" href="#module-ax.models.torch_base" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch_base.TorchModel">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch_base.</code><code class="sig-name descname">TorchModel</code><a class="reference internal" href="_modules/ax/models/torch_base.html#TorchModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch_base.TorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.base.Model" title="ax.models.base.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.base.Model</span></code></a></p>
<p>This class specifies the interface for a torch-based model.</p>
<p>These methods should be implemented to have access to all of the features
of Ax.</p>
<dl class="method">
<dt id="ax.models.torch_base.TorchModel.best_point">
<code class="sig-name descname">best_point</code><span class="sig-paren">(</span><em class="sig-param">bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Optional[torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch_base.html#TorchModel.best_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch_base.TorchModel.best_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Identify the current best point, satisfying the constraints in the same
format as to gen.</p>
<p>Return None if no such point can be identified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value in the best point.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>d-tensor of the best point.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch_base.TorchModel.cross_validate">
<code class="sig-name descname">cross_validate</code><span class="sig-paren">(</span><em class="sig-param">Xs_train: List[torch.Tensor], Ys_train: List[torch.Tensor], Yvars_train: List[torch.Tensor], X_test: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch_base.html#TorchModel.cross_validate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch_base.TorchModel.cross_validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Do cross validation with the given training and test sets.</p>
<p>Training set is given in the same format as to fit. Test set is given
in the same format as to predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs_train</strong> – A list of m (k_i x d) feature tensors X. Number of rows
k_i can vary from i=1,…,m.</p></li>
<li><p><strong>Ys_train</strong> – The corresponding list of m (k_i x 1) outcome tensors Y,
for each outcome.</p></li>
<li><p><strong>Yvars_train</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>X_test</strong> – (j x d) tensor of the j points at which to make predictions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) tensor of outcome predictions at X.</p></li>
<li><p>(j x m x m) tensor of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch_base.TorchModel.device">
<code class="sig-name descname">device</code><em class="property">: Optional[torch.device]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch_base.TorchModel.device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch_base.TorchModel.dtype">
<code class="sig-name descname">dtype</code><em class="property">: Optional[torch.dtype]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch_base.TorchModel.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch_base.TorchModel.evaluate_acquisition_function">
<code class="sig-name descname">evaluate_acquisition_function</code><span class="sig-paren">(</span><em class="sig-param">X: torch.Tensor</em><span class="sig-paren">)</span> → torch.Tensor<a class="reference internal" href="_modules/ax/models/torch_base.html#TorchModel.evaluate_acquisition_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch_base.TorchModel.evaluate_acquisition_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the acquisition function on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – (j x d) tensor of the j points at which to evaluate the acquisition
function.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A single-element tensor with the acquisition value for these points.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch_base.TorchModel.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], bounds: List[Tuple[float, float]], task_features: List[int], feature_names: List[str], metric_names: List[str], fidelity_features: List[int], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch_base.html#TorchModel.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch_base.TorchModel.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to m outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – A list of m (k_i x d) feature tensors X. Number of rows k_i can
vary from i=1,…,m.</p></li>
<li><p><strong>Ys</strong> – The corresponding list of m (k_i x 1) outcome tensors Y, for
each outcome.</p></li>
<li><p><strong>Yvars</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>bounds</strong> – A list of d (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>task_features</strong> – Columns of X that take integer values and should be
treated as task parameters.</p></li>
<li><p><strong>feature_names</strong> – Names of each column of X.</p></li>
<li><p><strong>metric_names</strong> – Names of each outcome Y in Ys.</p></li>
<li><p><strong>fidelity_features</strong> – Columns of X that should be treated as fidelity
parameters.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch_base.TorchModel.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, pending_observations: Optional[List[torch.Tensor]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor, Dict[str, Any], Optional[List[Optional[Dict[str, Any]]]]]<a class="reference internal" href="_modules/ax/models/torch_base.html#TorchModel.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch_base.TorchModel.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>pending_observations</strong> – A list of m (k_i x d) feature tensors X
for m outcomes and k_i pending observations for outcome i.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (i.e., according to <cite>round-trip</cite> transformations).</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>4-element tuple containing</p>
<ul class="simple">
<li><p>(n x d) tensor of generated points.</p></li>
<li><p>n-tensor of weights for each point.</p></li>
<li><p>Generation metadata</p></li>
<li><dl class="simple">
<dt>Dictionary of model-specific metadata for the given</dt><dd><p>generation candidates</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch_base.TorchModel.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch_base.html#TorchModel.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch_base.TorchModel.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – (j x d) tensor of the j points at which to make predictions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) tensor of outcome predictions at X.</p></li>
<li><p>(j x m x m) tensor of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch_base.TorchModel.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch_base.html#TorchModel.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch_base.TorchModel.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the model.</p>
<p>Updating the model requires both existing and additional data.
The data passed into this method will become the new training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>Ys</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>Yvars</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
</div>
<div class="section" id="discrete-models">
<h2>Discrete Models<a class="headerlink" href="#discrete-models" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-ax.models.discrete.eb_thompson">
<span id="ax-models-discrete-eb-thompson-module"></span><h3>ax.models.discrete.eb_thompson module<a class="headerlink" href="#module-ax.models.discrete.eb_thompson" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.discrete.eb_thompson.EmpiricalBayesThompsonSampler">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.discrete.eb_thompson.</code><code class="sig-name descname">EmpiricalBayesThompsonSampler</code><span class="sig-paren">(</span><em class="sig-param">num_samples: int = 10000</em>, <em class="sig-param">min_weight: Optional[float] = None</em>, <em class="sig-param">uniform_weights: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/discrete/eb_thompson.html#EmpiricalBayesThompsonSampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete.eb_thompson.EmpiricalBayesThompsonSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.discrete.thompson.ThompsonSampler" title="ax.models.discrete.thompson.ThompsonSampler"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.discrete.thompson.ThompsonSampler</span></code></a></p>
<p>Generator for Thompson sampling using Empirical Bayes estimates.</p>
<p>The generator applies positive-part James-Stein Estimator to the data
passed in via <cite>fit</cite> and then performs Thompson Sampling.</p>
</dd></dl>
</div>
<div class="section" id="module-ax.models.discrete.full_factorial">
<span id="ax-models-discrete-full-factorial-module"></span><h3>ax.models.discrete.full_factorial module<a class="headerlink" href="#module-ax.models.discrete.full_factorial" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.discrete.full_factorial.FullFactorialGenerator">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.discrete.full_factorial.</code><code class="sig-name descname">FullFactorialGenerator</code><span class="sig-paren">(</span><em class="sig-param">max_cardinality: int = 100</em>, <em class="sig-param">check_cardinality: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/discrete/full_factorial.html#FullFactorialGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete.full_factorial.FullFactorialGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.discrete_base.DiscreteModel" title="ax.models.discrete_base.DiscreteModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.discrete_base.DiscreteModel</span></code></a></p>
<p>Generator for full factorial designs.</p>
<p>Generates arms for all possible combinations of parameter values,
each with weight 1.</p>
<p>The value of n supplied to <cite>gen</cite> will be ignored, as the number
of arms generated is determined by the list of parameter values.
To suppress this warning, use n = -1.</p>
<dl class="method">
<dt id="ax.models.discrete.full_factorial.FullFactorialGenerator.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, parameter_values: List[List[Union[str, bool, float, int, None]]], objective_weights: Optional[numpy.ndarray], outcome_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, fixed_features: Optional[Dict[int, Union[str, bool, float, int, None]]] = None, pending_observations: Optional[List[List[List[Union[str, bool, float, int, None]]]]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None</em><span class="sig-paren">)</span> → Tuple[List[List[Union[str, bool, float, int, None]]], List[float], Dict[str, Any]]<a class="reference internal" href="_modules/ax/models/discrete/full_factorial.html#FullFactorialGenerator.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete.full_factorial.FullFactorialGenerator.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>parameter_values</strong> – A list of possible values for each parameter.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>pending_observations</strong> – A list of m lists of parameterizations
(each parameterization is a list of parameter values of length d),
each of length k_i, for each outcome i.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>List of n generated points, where each point is represented
by a list of parameter values.</p></li>
<li><p>List of weights for each of the n points.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.discrete.thompson">
<span id="ax-models-discrete-thompson-module"></span><h3>ax.models.discrete.thompson module<a class="headerlink" href="#module-ax.models.discrete.thompson" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.discrete.thompson.ThompsonSampler">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.discrete.thompson.</code><code class="sig-name descname">ThompsonSampler</code><span class="sig-paren">(</span><em class="sig-param">num_samples: int = 10000</em>, <em class="sig-param">min_weight: Optional[float] = None</em>, <em class="sig-param">uniform_weights: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/discrete/thompson.html#ThompsonSampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete.thompson.ThompsonSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.discrete_base.DiscreteModel" title="ax.models.discrete_base.DiscreteModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.discrete_base.DiscreteModel</span></code></a></p>
<p>Generator for Thompson sampling.</p>
<p>The generator performs Thompson sampling on the data passed in via <cite>fit</cite>.
Arms are given weight proportional to the probability that they are
winners, according to Monte Carlo simulations.</p>
<dl class="method">
<dt id="ax.models.discrete.thompson.ThompsonSampler.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[List[List[Union[str, bool, float, int, None]]]], Ys: List[List[float]], Yvars: List[List[float]], parameter_values: List[List[Union[str, bool, float, int, None]]], outcome_names: List[str]</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/discrete/thompson.html#ThompsonSampler.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete.thompson.ThompsonSampler.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to m outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – A list of m lists X of parameterizations (each parameterization
is a list of parameter values of length d), each of length k_i,
for each outcome.</p></li>
<li><p><strong>Ys</strong> – The corresponding list of m lists Y, each of length k_i, for
each outcome.</p></li>
<li><p><strong>Yvars</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>parameter_values</strong> – A list of possible values for each parameter.</p></li>
<li><p><strong>outcome_names</strong> – A list of m outcome names.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.discrete.thompson.ThompsonSampler.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, parameter_values: List[List[Union[str, bool, float, int, None]]], objective_weights: Optional[numpy.ndarray], outcome_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, fixed_features: Optional[Dict[int, Union[str, bool, float, int, None]]] = None, pending_observations: Optional[List[List[List[Union[str, bool, float, int, None]]]]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None</em><span class="sig-paren">)</span> → Tuple[List[List[Union[str, bool, float, int, None]]], List[float], Dict[str, Any]]<a class="reference internal" href="_modules/ax/models/discrete/thompson.html#ThompsonSampler.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete.thompson.ThompsonSampler.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>parameter_values</strong> – A list of possible values for each parameter.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>pending_observations</strong> – A list of m lists of parameterizations
(each parameterization is a list of parameter values of length d),
each of length k_i, for each outcome i.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>List of n generated points, where each point is represented
by a list of parameter values.</p></li>
<li><p>List of weights for each of the n points.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.discrete.thompson.ThompsonSampler.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X: List[List[Union[str, bool, float, int, None]]]</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/discrete/thompson.html#ThompsonSampler.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.discrete.thompson.ThompsonSampler.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – List of the j parameterizations at which to make predictions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) array of outcome predictions at X.</p></li>
<li><p>(j x m x m) array of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
</div>
<div class="section" id="numpy-models">
<h2>NumPy Models<a class="headerlink" href="#numpy-models" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-ax.models.numpy.randomforest">
<span id="ax-models-numpy-randomforest-module"></span><h3>ax.models.numpy.randomforest module<a class="headerlink" href="#module-ax.models.numpy.randomforest" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.numpy.randomforest.RandomForest">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.numpy.randomforest.</code><code class="sig-name descname">RandomForest</code><span class="sig-paren">(</span><em class="sig-param">max_features: Optional[str] = 'sqrt'</em>, <em class="sig-param">num_trees: int = 500</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/numpy/randomforest.html#RandomForest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.numpy.randomforest.RandomForest" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.numpy_base.NumpyModel" title="ax.models.numpy_base.NumpyModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.numpy_base.NumpyModel</span></code></a></p>
<p>A Random Forest model.</p>
<p>Uses a parametric bootstrap to handle uncertainty in Y.</p>
<p>Can be used to fit data, make predictions, and do cross validation; however
gen is not implemented and so this model cannot generate new points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_features</strong> – Maximum number of features at each split. With one-hot
encoding, this should be set to None. Defaults to “sqrt”, which is
Breiman’s version of Random Forest.</p></li>
<li><p><strong>num_trees</strong> – Number of trees.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="ax.models.numpy.randomforest.RandomForest.cross_validate">
<code class="sig-name descname">cross_validate</code><span class="sig-paren">(</span><em class="sig-param">Xs_train: List[numpy.ndarray], Ys_train: List[numpy.ndarray], Yvars_train: List[numpy.ndarray], X_test: numpy.ndarray</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/numpy/randomforest.html#RandomForest.cross_validate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.numpy.randomforest.RandomForest.cross_validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Do cross validation with the given training and test sets.</p>
<p>Training set is given in the same format as to fit. Test set is given
in the same format as to predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs_train</strong> – A list of m (k_i x d) feature matrices X. Number of rows
k_i can vary from i=1,…,m.</p></li>
<li><p><strong>Ys_train</strong> – The corresponding list of m (k_i x 1) outcome arrays Y,
for each outcome.</p></li>
<li><p><strong>Yvars_train</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>X_test</strong> – (j x d) array of the j points at which to make predictions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) array of outcome predictions at X.</p></li>
<li><p>(j x m x m) array of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.numpy.randomforest.RandomForest.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[numpy.ndarray], Ys: List[numpy.ndarray], Yvars: List[numpy.ndarray], bounds: List[Tuple[float, float]], task_features: List[int], feature_names: List[str], metric_names: List[str], fidelity_features: List[int], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/numpy/randomforest.html#RandomForest.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.numpy.randomforest.RandomForest.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to m outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – A list of m (k_i x d) feature matrices X. Number of rows k_i
can vary from i=1,…,m.</p></li>
<li><p><strong>Ys</strong> – The corresponding list of m (k_i x 1) outcome arrays Y, for
each outcome.</p></li>
<li><p><strong>Yvars</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>bounds</strong> – A list of d (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>task_features</strong> – Columns of X that take integer values and should be
treated as task parameters.</p></li>
<li><p><strong>feature_names</strong> – Names of each column of X.</p></li>
<li><p><strong>metric_names</strong> – Names of each outcome Y in Ys.</p></li>
<li><p><strong>fidelity_features</strong> – Columns of X that should be treated as fidelity
parameters.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.numpy.randomforest.RandomForest.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X: numpy.ndarray</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/numpy/randomforest.html#RandomForest.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.numpy.randomforest.RandomForest.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – (j x d) array of the j points at which to make predictions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) array of outcome predictions at X.</p></li>
<li><p>(j x m x m) array of predictive covariances at X.
<cite>cov[j, m1, m2]</cite> is <cite>Cov[m1@j, m2@j]</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
</div>
<div class="section" id="random-models">
<h2>Random Models<a class="headerlink" href="#random-models" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-ax.models.random.alebo_initializer">
<span id="ax-models-random-alebo-initializer-module"></span><h3>ax.models.random.alebo_initializer module<a class="headerlink" href="#module-ax.models.random.alebo_initializer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.random.alebo_initializer.ALEBOInitializer">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.random.alebo_initializer.</code><code class="sig-name descname">ALEBOInitializer</code><span class="sig-paren">(</span><em class="sig-param">B: numpy.ndarray</em>, <em class="sig-param">nsamp: int = 10000</em>, <em class="sig-param">init_bound: int = 16</em>, <em class="sig-param">**kwargs: Any</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/random/alebo_initializer.html#ALEBOInitializer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.random.alebo_initializer.ALEBOInitializer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.random.uniform.UniformGenerator" title="ax.models.random.uniform.UniformGenerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.random.uniform.UniformGenerator</span></code></a></p>
<p>Sample in a low-dimensional linear embedding, to initialize ALEBO.</p>
<p>Generates points on a linear subspace of [-1, 1]^D by generating points in
[-b, b]^D, projecting them down with a matrix B, and then projecting them
back up with the pseudoinverse of B. Thus points thus all lie in a linear
subspace defined by B. Points whose up-projection falls outside of [-1, 1]^D
are thrown out, via rejection sampling.</p>
<p>To generate n points, we start with nsamp points in [-b, b]^D, which are
mapped down to the embedding and back up as described above. If &gt;=n points
fall within [-1, 1]^D after being mapped up, then the first n are returned.
If there are less than n points in [-1, 1]^D, then b is constricted
(halved) and the process is repeated until there are at least n points in
[-1, 1]^D. There exists a b small enough that all points will project to
[-1, 1]^D, so this is guaranteed to terminate, typically after few rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>B</strong> – A (dxD) projection down.</p></li>
<li><p><strong>nsamp</strong> – Number of samples to use for rejection sampling.</p></li>
<li><p><strong>init_bound</strong> – b for the initial sampling space described above.</p></li>
<li><p><strong>kwargs</strong> – kwargs for UniformGenerator</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="ax.models.random.alebo_initializer.ALEBOInitializer.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List[Tuple[float, float]], linear_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[numpy.ndarray], numpy.ndarray]] = None</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/random/alebo_initializer.html#ALEBOInitializer.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.random.alebo_initializer.ALEBOInitializer.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.
Defined on [0, 1]^d.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that is passed along to the
model.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (e.g., according to <cite>round-trip</cite> transformations).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(n x d) array of generated points.</p></li>
<li><p>Uniform weights, an n-array of ones for each point.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.random.base">
<span id="ax-models-random-base-module"></span><h3>ax.models.random.base module<a class="headerlink" href="#module-ax.models.random.base" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.random.base.RandomModel">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.random.base.</code><code class="sig-name descname">RandomModel</code><span class="sig-paren">(</span><em class="sig-param">deduplicate: bool = True</em>, <em class="sig-param">seed: Optional[int] = None</em>, <em class="sig-param">generated_points: Optional[numpy.ndarray] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/random/base.html#RandomModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.random.base.RandomModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.base.Model" title="ax.models.base.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.base.Model</span></code></a></p>
<p>This class specifies the basic skeleton for a random model.</p>
<p>As random generators do not make use of models, they do not implement
the fit or predict methods.</p>
<p>These models do not need data, or optimization configs.</p>
<p>To satisfy search space parameter constraints, these models can use
rejection sampling. To enable rejection sampling for a subclass, only
only <cite>_gen_samples</cite> needs to be implemented, or alternatively,
<cite>_gen_unconstrained</cite>/<cite>gen</cite> can be directly implemented.</p>
<dl class="attribute">
<dt id="ax.models.random.base.RandomModel.deduplicate">
<code class="sig-name descname">deduplicate</code><a class="headerlink" href="#ax.models.random.base.RandomModel.deduplicate" title="Permalink to this definition">¶</a></dt>
<dd><p>If True (defaults to True), a single instantiation
of the model will not return the same point twice. This flag
is used in rejection sampling.</p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.random.base.RandomModel.scramble">
<code class="sig-name descname">scramble</code><a class="headerlink" href="#ax.models.random.base.RandomModel.scramble" title="Permalink to this definition">¶</a></dt>
<dd><p>If True, permutes the parameter values among
the elements of the Sobol sequence. Default is True.</p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.random.base.RandomModel.seed">
<code class="sig-name descname">seed</code><a class="headerlink" href="#ax.models.random.base.RandomModel.seed" title="Permalink to this definition">¶</a></dt>
<dd><p>An optional seed value for scrambling.</p>
</dd></dl>
<dl class="method">
<dt id="ax.models.random.base.RandomModel.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List[Tuple[float, float]], linear_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[numpy.ndarray], numpy.ndarray]] = None</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/random/base.html#RandomModel.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.random.base.RandomModel.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.
Defined on [0, 1]^d.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that is passed along to the
model.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (e.g., according to <cite>round-trip</cite> transformations).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(n x d) array of generated points.</p></li>
<li><p>Uniform weights, an n-array of ones for each point.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.random.rembo_initializer">
<span id="ax-models-random-rembo-initializer-module"></span><h3>ax.models.random.rembo_initializer module<a class="headerlink" href="#module-ax.models.random.rembo_initializer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.random.rembo_initializer.REMBOInitializer">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.random.rembo_initializer.</code><code class="sig-name descname">REMBOInitializer</code><span class="sig-paren">(</span><em class="sig-param">A: numpy.ndarray, bounds_d: List[Tuple[float, float]], **kwargs: Any</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/random/rembo_initializer.html#REMBOInitializer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.random.rembo_initializer.REMBOInitializer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.random.uniform.UniformGenerator" title="ax.models.random.uniform.UniformGenerator"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.random.uniform.UniformGenerator</span></code></a></p>
<p>Sample in a low-dimensional linear embedding.</p>
<p>Generates points in [-1, 1]^D by generating points in a d-dimensional
embedding, with box bounds as specified. When points are projected up, if
they fall outside [-1, 1]^D they are clamped to those bounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> – A (Dxd) linear embedding</p></li>
<li><p><strong>bounds_d</strong> – Box bounds in the low-d space</p></li>
<li><p><strong>kwargs</strong> – kwargs for UniformGenerator</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="ax.models.random.rembo_initializer.REMBOInitializer.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List[Tuple[float, float]], linear_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[numpy.ndarray], numpy.ndarray]] = None</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/random/rembo_initializer.html#REMBOInitializer.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.random.rembo_initializer.REMBOInitializer.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.
Defined on [0, 1]^d.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that is passed along to the
model.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (e.g., according to <cite>round-trip</cite> transformations).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(n x d) array of generated points.</p></li>
<li><p>Uniform weights, an n-array of ones for each point.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.random.rembo_initializer.REMBOInitializer.project_up">
<code class="sig-name descname">project_up</code><span class="sig-paren">(</span><em class="sig-param">X: numpy.ndarray</em><span class="sig-paren">)</span> → numpy.ndarray<a class="reference internal" href="_modules/ax/models/random/rembo_initializer.html#REMBOInitializer.project_up"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.random.rembo_initializer.REMBOInitializer.project_up" title="Permalink to this definition">¶</a></dt>
<dd><p>Project to high-dimensional space.</p>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.random.sobol">
<span id="ax-models-random-sobol-module"></span><h3>ax.models.random.sobol module<a class="headerlink" href="#module-ax.models.random.sobol" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.random.sobol.SobolGenerator">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.random.sobol.</code><code class="sig-name descname">SobolGenerator</code><span class="sig-paren">(</span><em class="sig-param">seed: Optional[int] = None</em>, <em class="sig-param">deduplicate: bool = False</em>, <em class="sig-param">init_position: int = 0</em>, <em class="sig-param">scramble: bool = True</em>, <em class="sig-param">generated_points: Optional[numpy.ndarray] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/random/sobol.html#SobolGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.random.sobol.SobolGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.random.base.RandomModel" title="ax.models.random.base.RandomModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.random.base.RandomModel</span></code></a></p>
<p>This class specifies the generation algorithm for a Sobol generator.</p>
<p>As Sobol does not make use of a model, it does not implement
the fit or predict methods.</p>
<dl class="attribute">
<dt id="ax.models.random.sobol.SobolGenerator.deduplicate">
<code class="sig-name descname">deduplicate</code><a class="headerlink" href="#ax.models.random.sobol.SobolGenerator.deduplicate" title="Permalink to this definition">¶</a></dt>
<dd><p>If true, a single instantiation of the generator will not
return the same point twice.</p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.random.sobol.SobolGenerator.init_position">
<code class="sig-name descname">init_position</code><a class="headerlink" href="#ax.models.random.sobol.SobolGenerator.init_position" title="Permalink to this definition">¶</a></dt>
<dd><p>The initial state of the Sobol generator.
Starts at 0 by default.</p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.random.sobol.SobolGenerator.scramble">
<code class="sig-name descname">scramble</code><a class="headerlink" href="#ax.models.random.sobol.SobolGenerator.scramble" title="Permalink to this definition">¶</a></dt>
<dd><p>If True, permutes the parameter values among
the elements of the Sobol sequence. Default is True.</p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.random.sobol.SobolGenerator.seed">
<code class="sig-name descname">seed</code><a class="headerlink" href="#ax.models.random.sobol.SobolGenerator.seed" title="Permalink to this definition">¶</a></dt>
<dd><p>An optional seed value for scrambling.</p>
</dd></dl>
<dl class="method">
<dt id="ax.models.random.sobol.SobolGenerator.engine">
<em class="property">property </em><code class="sig-name descname">engine</code><a class="headerlink" href="#ax.models.random.sobol.SobolGenerator.engine" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a singleton SobolEngine.</p>
</dd></dl>
<dl class="method">
<dt id="ax.models.random.sobol.SobolGenerator.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List[Tuple[float, float]], linear_constraints: Optional[Tuple[numpy.ndarray, numpy.ndarray]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[numpy.ndarray], numpy.ndarray]] = None</em><span class="sig-paren">)</span> → Tuple[numpy.ndarray, numpy.ndarray]<a class="reference internal" href="_modules/ax/models/random/sobol.html#SobolGenerator.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.random.sobol.SobolGenerator.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (e.g., according to <cite>round-trip</cite> transformations)
but <em>unused here</em>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(n x d) array of generated points.</p></li>
<li><p>Uniform weights, an n-array of ones for each point.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.random.sobol.SobolGenerator.init_engine">
<code class="sig-name descname">init_engine</code><span class="sig-paren">(</span><em class="sig-param">n_tunable_features: int</em><span class="sig-paren">)</span> → torch.quasirandom.SobolEngine<a class="reference internal" href="_modules/ax/models/random/sobol.html#SobolGenerator.init_engine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.random.sobol.SobolGenerator.init_engine" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize singleton SobolEngine, only on gen.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n_tunable_features</strong> – The number of features which can be
searched over.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>SobolEngine, which can generate Sobol points.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.random.uniform">
<span id="ax-models-random-uniform-module"></span><h3>ax.models.random.uniform module<a class="headerlink" href="#module-ax.models.random.uniform" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.random.uniform.UniformGenerator">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.random.uniform.</code><code class="sig-name descname">UniformGenerator</code><span class="sig-paren">(</span><em class="sig-param">deduplicate: bool = False</em>, <em class="sig-param">seed: Optional[int] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/random/uniform.html#UniformGenerator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.random.uniform.UniformGenerator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.random.base.RandomModel" title="ax.models.random.base.RandomModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.random.base.RandomModel</span></code></a></p>
<p>This class specifies a uniform random generation algorithm.</p>
<p>As a uniform generator does not make use of a model, it does not implement
the fit or predict methods.</p>
<dl class="attribute">
<dt id="ax.models.random.uniform.UniformGenerator.seed">
<code class="sig-name descname">seed</code><a class="headerlink" href="#ax.models.random.uniform.UniformGenerator.seed" title="Permalink to this definition">¶</a></dt>
<dd><p>An optional seed value for the underlying PRNG.</p>
</dd></dl>
</dd></dl>
</div>
</div>
<div class="section" id="torch-models">
<h2>Torch Models<a class="headerlink" href="#torch-models" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-ax.models.torch.alebo">
<span id="ax-models-torch-alebo-module"></span><h3>ax.models.torch.alebo module<a class="headerlink" href="#module-ax.models.torch.alebo" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.alebo.ALEBO">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.alebo.</code><code class="sig-name descname">ALEBO</code><span class="sig-paren">(</span><em class="sig-param">B: torch.Tensor</em>, <em class="sig-param">laplace_nsamp: int = 25</em>, <em class="sig-param">fit_restarts: int = 10</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/alebo.html#ALEBO"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ALEBO" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch.BotorchModel" title="ax.models.torch.botorch.BotorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch.BotorchModel</span></code></a></p>
<p>Does Bayesian optimization in a linear subspace with ALEBO.</p>
<p>The (d x D) projection down matrix B must be provided, and must be that
used for the initialization.</p>
<p>Function evaluations happen in the high-D space. We only evaluate points
such that x = pinverse(B) @ B @ x (that is, points inside the subspace).
Under that constraint, the projection is invertible.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>B</strong> – (d x D) projection matrix (projects down).</p></li>
<li><p><strong>laplace_nsamp</strong> – Number of samples for posterior sampling of kernel
hyperparameters.</p></li>
<li><p><strong>fit_restarts</strong> – Number of random restarts for MAP estimation.</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="ax.models.torch.alebo.ALEBO.Xs">
<code class="sig-name descname">Xs</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.alebo.ALEBO.Xs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.alebo.ALEBO.Ys">
<code class="sig-name descname">Ys</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.alebo.ALEBO.Ys" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.alebo.ALEBO.Yvars">
<code class="sig-name descname">Yvars</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.alebo.ALEBO.Yvars" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.alebo.ALEBO.best_point">
<code class="sig-name descname">best_point</code><span class="sig-paren">(</span><em class="sig-param">bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Optional[torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/alebo.html#ALEBO.best_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ALEBO.best_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Identify the current best point, satisfying the constraints in the same
format as to gen.</p>
<p>Return None if no such point can be identified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value in the best point.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>d-tensor of the best point.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.alebo.ALEBO.cross_validate">
<code class="sig-name descname">cross_validate</code><span class="sig-paren">(</span><em class="sig-param">Xs_train: List[torch.Tensor], Ys_train: List[torch.Tensor], Yvars_train: List[torch.Tensor], X_test: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/alebo.html#ALEBO.cross_validate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ALEBO.cross_validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Do cross validation with the given training and test sets.</p>
<p>Training set is given in the same format as to fit. Test set is given
in the same format as to predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs_train</strong> – A list of m (k_i x d) feature tensors X. Number of rows
k_i can vary from i=1,…,m.</p></li>
<li><p><strong>Ys_train</strong> – The corresponding list of m (k_i x 1) outcome tensors Y,
for each outcome.</p></li>
<li><p><strong>Yvars_train</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>X_test</strong> – (j x d) tensor of the j points at which to make predictions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) tensor of outcome predictions at X.</p></li>
<li><p>(j x m x m) tensor of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.alebo.ALEBO.device">
<code class="sig-name descname">device</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.alebo.ALEBO.device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.alebo.ALEBO.dtype">
<code class="sig-name descname">dtype</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.alebo.ALEBO.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.alebo.ALEBO.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], bounds: List[Tuple[float, float]], task_features: List[int], feature_names: List[str], metric_names: List[str], fidelity_features: List[int], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/alebo.html#ALEBO.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ALEBO.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to m outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – A list of m (k_i x d) feature tensors X. Number of rows k_i can
vary from i=1,…,m.</p></li>
<li><p><strong>Ys</strong> – The corresponding list of m (k_i x 1) outcome tensors Y, for
each outcome.</p></li>
<li><p><strong>Yvars</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>bounds</strong> – A list of d (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>task_features</strong> – Columns of X that take integer values and should be
treated as task parameters.</p></li>
<li><p><strong>feature_names</strong> – Names of each column of X.</p></li>
<li><p><strong>metric_names</strong> – Names of each outcome Y in Ys.</p></li>
<li><p><strong>fidelity_features</strong> – Columns of X that should be treated as fidelity
parameters.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.alebo.ALEBO.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, pending_observations: Optional[List[torch.Tensor]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor, Dict[str, Any], List[Optional[Dict[str, Any]]]]<a class="reference internal" href="_modules/ax/models/torch/alebo.html#ALEBO.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ALEBO.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate candidates.</p>
<p>Candidates are generated in the linear embedding with the polytope
constraints described in the paper.</p>
<p>model_gen_options can contain ‘raw_samples’ (number of samples used for
initializing the acquisition function optimization) and ‘num_restarts’
(number of restarts for acquisition function optimization).</p>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.alebo.ALEBO.get_and_fit_model">
<code class="sig-name descname">get_and_fit_model</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], state_dicts: Optional[List[MutableMapping[str, torch.Tensor]]] = None</em><span class="sig-paren">)</span> → botorch.models.gpytorch.GPyTorchModel<a class="reference internal" href="_modules/ax/models/torch/alebo.html#ALEBO.get_and_fit_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ALEBO.get_and_fit_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a fitted ALEBO model for each outcome.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – X for each outcome, already projected down.</p></li>
<li><p><strong>Ys</strong> – Y for each outcome.</p></li>
<li><p><strong>Yvars</strong> – Noise variance of Y for each outcome.</p></li>
<li><p><strong>state_dicts</strong> – State dicts to initialize model fitting.</p></li>
</ul>
</dd>
</dl>
<p>Returns: Fitted ALEBO model.</p>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.alebo.ALEBO.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/alebo.html#ALEBO.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ALEBO.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – (j x d) tensor of the j points at which to make predictions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) tensor of outcome predictions at X.</p></li>
<li><p>(j x m x m) tensor of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.alebo.ALEBO.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/alebo.html#ALEBO.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ALEBO.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the model.</p>
<p>Updating the model requires both existing and additional data.
The data passed into this method will become the new training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>Ys</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>Yvars</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="ax.models.torch.alebo.ALEBOGP">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.alebo.</code><code class="sig-name descname">ALEBOGP</code><span class="sig-paren">(</span><em class="sig-param">B: torch.Tensor</em>, <em class="sig-param">train_X: torch.Tensor</em>, <em class="sig-param">train_Y: torch.Tensor</em>, <em class="sig-param">train_Yvar: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/alebo.html#ALEBOGP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ALEBOGP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.models.gp_regression.FixedNoiseGP</span></code></p>
<p>The GP for ALEBO.</p>
<p>Uses the Mahalanobis kernel defined in ALEBOKernel, along with a
ScaleKernel to add a kernel variance and a fitted constant mean.</p>
<p>In non-batch mode, there is a single kernel that produces MVN predictions
as usual for a GP.
With b batches, each batch has its own set of kernel hyperparameters and
each batch represents a sample from the hyperparameter posterior
distribution. When making a prediction (with <cite>__call__</cite>), these samples are
integrated over using moment matching. So, the predictions are an MVN as
usual with the same shape as in non-batch mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>B</strong> – (d x D) Projection matrix.</p></li>
<li><p><strong>train_X</strong> – (n x d) X training data.</p></li>
<li><p><strong>train_Y</strong> – (n x 1) Y training data.</p></li>
<li><p><strong>train_Yvar</strong> – (n x 1) Noise variances of each training Y.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="ax.models.torch.alebo.ALEBOGP.posterior">
<code class="sig-name descname">posterior</code><span class="sig-paren">(</span><em class="sig-param">X: torch.Tensor</em>, <em class="sig-param">output_indices: Optional[List[int]] = None</em>, <em class="sig-param">observation_noise: Union[bool</em>, <em class="sig-param">torch.Tensor] = False</em>, <em class="sig-param">**kwargs: Any</em><span class="sig-paren">)</span> → botorch.posteriors.gpytorch.GPyTorchPosterior<a class="reference internal" href="_modules/ax/models/torch/alebo.html#ALEBOGP.posterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ALEBOGP.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the posterior over model outputs at the provided points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – A <cite>(batch_shape) x q x d</cite>-dim Tensor, where <cite>d</cite> is the dimension
of the feature space and <cite>q</cite> is the number of points considered
jointly.</p></li>
<li><p><strong>output_indices</strong> – A list of indices, corresponding to the outputs over
which to compute the posterior (if the model is multi-output).
Can be used to speed up computation if only a subset of the
model’s outputs are required for optimization. If omitted,
computes the posterior over all model outputs.</p></li>
<li><p><strong>observation_noise</strong> – If True, add the observation noise from the
likelihood to the posterior. If a Tensor, use it directly as the
observation noise (must be of shape <cite>(batch_shape) x q x m</cite>).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>GPyTorchPosterior</cite> object, representing <cite>batch_shape</cite> joint
distributions over <cite>q</cite> points and the outputs selected by
<cite>output_indices</cite> each. Includes observation noise if specified.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="ax.models.torch.alebo.ALEBOKernel">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.alebo.</code><code class="sig-name descname">ALEBOKernel</code><span class="sig-paren">(</span><em class="sig-param">B: torch.Tensor</em>, <em class="sig-param">batch_shape: torch.Size</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/alebo.html#ALEBOKernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ALEBOKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">gpytorch.kernels.kernel.Kernel</span></code></p>
<p>The kernel for ALEBO.</p>
<p>Suppose there exists an ARD RBF GP on an (unknown) linear embedding with
projection matrix A. We make function evaluations in a different linear
embedding with projection matrix B (known). This is the appropriate kernel
for fitting those data.</p>
<p>This kernel computes a Mahalanobis distance, and the (d x d) PD distance
matrix Gamma is a parameter that must be fit. This is done by fitting its
upper Cholesky decomposition, U.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>B</strong> – (d x D) Projection matrix.</p></li>
<li><p><strong>batch_shape</strong> – Batch shape as usual for gpytorch kernels.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="ax.models.torch.alebo.ALEBOKernel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x1: torch.Tensor</em>, <em class="sig-param">x2: torch.Tensor</em>, <em class="sig-param">diag: bool = False</em>, <em class="sig-param">last_dim_is_batch: bool = False</em>, <em class="sig-param">**params: Any</em><span class="sig-paren">)</span> → torch.Tensor<a class="reference internal" href="_modules/ax/models/torch/alebo.html#ALEBOKernel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ALEBOKernel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute kernel distance.</p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.alebo.ALEBOKernel.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.alebo.ALEBOKernel.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.alebo.alebo_acqf_optimizer">
<code class="sig-prename descclassname">ax.models.torch.alebo.</code><code class="sig-name descname">alebo_acqf_optimizer</code><span class="sig-paren">(</span><em class="sig-param">acq_function: botorch.acquisition.acquisition.AcquisitionFunction, bounds: torch.Tensor, n: int, inequality_constraints: Optional[List[Tuple[torch.Tensor, torch.Tensor, float]]], fixed_features: Optional[Dict[int, float]], rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]], raw_samples: int, num_restarts: int, B: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/alebo.html#alebo_acqf_optimizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.alebo_acqf_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Optimize the acquisition function for ALEBO.</p>
<p>We are optimizing over a polytope within the subspace, and so begin each
random restart of the acquisition function optimization with points that
lie within that polytope.</p>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.alebo.ei_or_nei">
<code class="sig-prename descclassname">ax.models.torch.alebo.</code><code class="sig-name descname">ei_or_nei</code><span class="sig-paren">(</span><em class="sig-param">model: Union[ax.models.torch.alebo.ALEBOGP, botorch.models.model_list_gp_regression.ModelListGP], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]], X_observed: torch.Tensor, X_pending: Optional[torch.Tensor], q: int, noiseless: bool</em><span class="sig-paren">)</span> → botorch.acquisition.acquisition.AcquisitionFunction<a class="reference internal" href="_modules/ax/models/torch/alebo.html#ei_or_nei"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.ei_or_nei" title="Permalink to this definition">¶</a></dt>
<dd><p>Use analytic EI if appropriate, otherwise Monte Carlo NEI.</p>
<p>Analytic EI can be used if: Single outcome, no constraints, no pending
points, not batch, and no noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – GP.</p></li>
<li><p><strong>objective_weights</strong> – Weights on each outcome for the objective.</p></li>
<li><p><strong>outcome_constraints</strong> – Outcome constraints.</p></li>
<li><p><strong>X_observed</strong> – Observed points for NEI.</p></li>
<li><p><strong>X_pending</strong> – Pending points.</p></li>
<li><p><strong>q</strong> – Batch size.</p></li>
<li><p><strong>noiseless</strong> – True if evaluations are noiseless.</p></li>
</ul>
</dd>
</dl>
<p>Returns: An AcquisitionFunction, either analytic EI or MC NEI.</p>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.alebo.extract_map_statedict">
<code class="sig-prename descclassname">ax.models.torch.alebo.</code><code class="sig-name descname">extract_map_statedict</code><span class="sig-paren">(</span><em class="sig-param">m_b: Union[ax.models.torch.alebo.ALEBOGP, botorch.models.model_list_gp_regression.ModelListGP], num_outputs: int</em><span class="sig-paren">)</span> → List[MutableMapping[str, torch.Tensor]]<a class="reference internal" href="_modules/ax/models/torch/alebo.html#extract_map_statedict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.extract_map_statedict" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract MAP statedict from the batch-mode ALEBO GP.</p>
<p>The batch GP can be either a single ALEBO GP or a ModelListGP of ALEBO GPs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>m_b</strong> – Batch-mode GP.</p></li>
<li><p><strong>num_outputs</strong> – Number of outputs being modeled.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.alebo.get_batch_model">
<code class="sig-prename descclassname">ax.models.torch.alebo.</code><code class="sig-name descname">get_batch_model</code><span class="sig-paren">(</span><em class="sig-param">B: torch.Tensor</em>, <em class="sig-param">train_X: torch.Tensor</em>, <em class="sig-param">train_Y: torch.Tensor</em>, <em class="sig-param">train_Yvar: torch.Tensor</em>, <em class="sig-param">Uvec_batch: torch.Tensor</em>, <em class="sig-param">mean_constant_batch: torch.Tensor</em>, <em class="sig-param">output_scale_batch: torch.Tensor</em><span class="sig-paren">)</span> → ax.models.torch.alebo.ALEBOGP<a class="reference internal" href="_modules/ax/models/torch/alebo.html#get_batch_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.get_batch_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a batch-mode ALEBO GP using batch tensors of hyperparameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>B</strong> – Projection matrix.</p></li>
<li><p><strong>train_X</strong> – X training data.</p></li>
<li><p><strong>train_Y</strong> – Y training data.</p></li>
<li><p><strong>train_Yvar</strong> – Noise variances of each training Y.</p></li>
<li><p><strong>Uvec_batch</strong> – Batch tensor of Uvec hyperparameters.</p></li>
<li><p><strong>mean_constant_batch</strong> – Batch tensor of mean constant hyperparameter.</p></li>
<li><p><strong>output_scale_batch</strong> – Batch tensor of output scale hyperparameter.</p></li>
</ul>
</dd>
</dl>
<p>Returns: Batch-mode ALEBO GP.</p>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.alebo.get_fitted_model">
<code class="sig-prename descclassname">ax.models.torch.alebo.</code><code class="sig-name descname">get_fitted_model</code><span class="sig-paren">(</span><em class="sig-param">B: torch.Tensor, train_X: torch.Tensor, train_Y: torch.Tensor, train_Yvar: torch.Tensor, restarts: int, nsamp: int, init_state_dict: Optional[Dict[str, torch.Tensor]]</em><span class="sig-paren">)</span> → ax.models.torch.alebo.ALEBOGP<a class="reference internal" href="_modules/ax/models/torch/alebo.html#get_fitted_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.get_fitted_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a fitted ALEBO GP.</p>
<p>We do random restart optimization to get a MAP model, then use the Laplace
approximation to draw posterior samples of kernel hyperparameters, and
finally construct a batch-mode model where each batch is one of those
sampled sets of kernel hyperparameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>B</strong> – Projection matrix.</p></li>
<li><p><strong>train_X</strong> – X training data.</p></li>
<li><p><strong>train_Y</strong> – Y training data.</p></li>
<li><p><strong>train_Yvar</strong> – Noise variances of each training Y.</p></li>
<li><p><strong>restarts</strong> – Number of restarts for MAP estimation.</p></li>
<li><p><strong>nsamp</strong> – Number of samples to draw from kernel hyperparameter posterior.</p></li>
<li><p><strong>init_state_dict</strong> – Optionally begin MAP estimation with this state dict.</p></li>
</ul>
</dd>
</dl>
<p>Returns: Batch-mode (nsamp batches) fitted ALEBO GP.</p>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.alebo.get_map_model">
<code class="sig-prename descclassname">ax.models.torch.alebo.</code><code class="sig-name descname">get_map_model</code><span class="sig-paren">(</span><em class="sig-param">B: torch.Tensor, train_X: torch.Tensor, train_Y: torch.Tensor, train_Yvar: torch.Tensor, restarts: int, init_state_dict: Optional[Dict[str, torch.Tensor]]</em><span class="sig-paren">)</span> → gpytorch.mlls.exact_marginal_log_likelihood.ExactMarginalLogLikelihood<a class="reference internal" href="_modules/ax/models/torch/alebo.html#get_map_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.get_map_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Do random-restart optimization for MAP fitting of an ALEBO GP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>B</strong> – Projection matrix.</p></li>
<li><p><strong>train_X</strong> – X training data.</p></li>
<li><p><strong>train_Y</strong> – Y training data.</p></li>
<li><p><strong>train_Yvar</strong> – Noise variances of each training Y.</p></li>
<li><p><strong>restarts</strong> – Number of restarts for MAP estimation.</p></li>
<li><p><strong>init_state_dict</strong> – Optionally begin MAP estimation with this state dict.</p></li>
</ul>
</dd>
</dl>
<p>Returns: non-batch ALEBO GP with MAP kernel hyperparameters.</p>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.alebo.laplace_sample_U">
<code class="sig-prename descclassname">ax.models.torch.alebo.</code><code class="sig-name descname">laplace_sample_U</code><span class="sig-paren">(</span><em class="sig-param">mll: gpytorch.mlls.exact_marginal_log_likelihood.ExactMarginalLogLikelihood</em>, <em class="sig-param">nsamp: int</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/alebo.html#laplace_sample_U"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.alebo.laplace_sample_U" title="Permalink to this definition">¶</a></dt>
<dd><p>Draw posterior samples of kernel hyperparameters using Laplace
approximation.</p>
<p>Only the Mahalanobis distance matrix is sampled.</p>
<p>The diagonal of the Hessian is estimated using finite differences of the
autograd gradients. The Laplace approximation is then N(p_map, inv(-H)).
We construct a set of nsamp kernel hyperparameters by drawing nsamp-1
values from this distribution, and prepending as the first sample the MAP
parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> – MLL object of MAP ALEBO GP.</p></li>
<li><p><strong>nsamp</strong> – Number of samples to return.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Returns: Batch tensors of the kernel hyperparameters Uvec, mean constant,</dt><dd><p>and output scale.</p>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch">
<span id="ax-models-torch-botorch-module"></span><h3>ax.models.torch.botorch module<a class="headerlink" href="#module-ax.models.torch.botorch" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.botorch.BotorchModel">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch.</code><code class="sig-name descname">BotorchModel</code><span class="sig-paren">(</span><em class="sig-param">model_constructor: Callable[[List[torch.Tensor], List[torch.Tensor], List[torch.Tensor], List[int], List[int], List[str], Optional[Dict[str, torch.Tensor]], Any], botorch.models.model.Model] = &lt;function get_and_fit_model&gt;, model_predictor: Callable[[botorch.models.model.Model, torch.Tensor], Tuple[torch.Tensor, torch.Tensor]] = &lt;function predict_from_model&gt;, acqf_constructor: Callable[[botorch.models.model.Model, torch.Tensor, Optional[Tuple[torch.Tensor, torch.Tensor]], Optional[torch.Tensor], Optional[torch.Tensor], Any], botorch.acquisition.acquisition.AcquisitionFunction] = &lt;function get_NEI&gt;, acqf_optimizer: Callable[[botorch.acquisition.acquisition.AcquisitionFunction, torch.Tensor, int, Optional[List[Tuple[torch.Tensor, torch.Tensor, float]]], Optional[Dict[int, float]], Optional[Callable[[torch.Tensor], torch.Tensor]], Any], Tuple[torch.Tensor, torch.Tensor]] = &lt;function scipy_optimizer&gt;, best_point_recommender: Callable[[ax.models.torch_base.TorchModel, List[Tuple[float, float]], torch.Tensor, Optional[Tuple[torch.Tensor, torch.Tensor]], Optional[Tuple[torch.Tensor, torch.Tensor]], Optional[Dict[int, float]], Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]], Optional[Dict[int, float]]], Optional[torch.Tensor]] = &lt;function recommend_best_observed_point&gt;, refit_on_cv: bool = False, refit_on_update: bool = True, warm_start_refitting: bool = True, use_input_warping: bool = False, **kwargs: Any</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch.html#BotorchModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch_base.TorchModel" title="ax.models.torch_base.TorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch_base.TorchModel</span></code></a></p>
<p>Customizable botorch model.</p>
<p>By default, this uses a noisy Expected Improvement acquisition function on
top of a model made up of separate GPs, one for each outcome. This behavior
can be modified by providing custom implementations of the following
components:</p>
<ul class="simple">
<li><p>a <cite>model_constructor</cite> that instantiates and fits a model on data</p></li>
<li><p>a <cite>model_predictor</cite> that predicts outcomes using the fitted model</p></li>
<li><p>a <cite>acqf_constructor</cite> that creates an acquisition function from a fitted model</p></li>
<li><p>a <cite>acqf_optimizer</cite> that optimizes the acquisition function</p></li>
<li><dl class="simple">
<dt>a <cite>best_point_recommender</cite> that recommends a current “best” point (i.e.,</dt><dd><p>what the model recommends if the learning process ended now)</p>
</dd>
</dl>
</li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_constructor</strong> – A callable that instantiates and fits a model on data,
with signature as described below.</p></li>
<li><p><strong>model_predictor</strong> – A callable that predicts using the fitted model, with
signature as described below.</p></li>
<li><p><strong>acqf_constructor</strong> – A callable that creates an acquisition function from a
fitted model, with signature as described below.</p></li>
<li><p><strong>acqf_optimizer</strong> – A callable that optimizes the acquisition function, with
signature as described below.</p></li>
<li><p><strong>best_point_recommender</strong> – A callable that recommends the best point, with
signature as described below.</p></li>
<li><p><strong>refit_on_cv</strong> – If True, refit the model for each fold when performing
cross-validation.</p></li>
<li><p><strong>refit_on_update</strong> – If True, refit the model after updating the training
data using the <cite>update</cite> method.</p></li>
<li><p><strong>warm_start_refitting</strong> – If True, start model refitting from previous
model parameters in order to speed up the fitting process.</p></li>
</ul>
</dd>
</dl>
<p>Call signatures:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_constructor</span><span class="p">(</span>
    <span class="n">Xs</span><span class="p">,</span>
    <span class="n">Ys</span><span class="p">,</span>
    <span class="n">Yvars</span><span class="p">,</span>
    <span class="n">task_features</span><span class="p">,</span>
    <span class="n">fidelity_features</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="p">,</span>
    <span class="n">state_dict</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">model</span>
</pre></div>
</div>
<p>Here <cite>Xs</cite>, <cite>Ys</cite>, <cite>Yvars</cite> are lists of tensors (one element per outcome),
<cite>task_features</cite> identifies columns of Xs that should be modeled as a task,
<cite>fidelity_features</cite> is a list of ints that specify the positions of fidelity
parameters in ‘Xs’, <cite>metric_names</cite> provides the names of each <cite>Y</cite> in <cite>Ys</cite>,
<cite>state_dict</cite> is a pytorch module state dict, and <cite>model</cite> is a BoTorch <cite>Model</cite>.
Optional kwargs are being passed through from the <cite>BotorchModel</cite> constructor.
This callable is assumed to return a fitted BoTorch model that has the same
dtype and lives on the same device as the input tensors.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_predictor</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">[</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">]</span>
</pre></div>
</div>
<p>Here <cite>model</cite> is a fitted botorch model, <cite>X</cite> is a tensor of candidate points,
and <cite>mean</cite> and <cite>cov</cite> are the posterior mean and covariance, respectively.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">acqf_constructor</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">objective_weights</span><span class="p">,</span>
    <span class="n">outcome_constraints</span><span class="p">,</span>
    <span class="n">X_observed</span><span class="p">,</span>
    <span class="n">X_pending</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">acq_function</span>
</pre></div>
</div>
<p>Here <cite>model</cite> is a botorch <cite>Model</cite>, <cite>objective_weights</cite> is a tensor of weights
for the model outputs, <cite>outcome_constraints</cite> is a tuple of tensors describing
the (linear) outcome constraints, <cite>X_observed</cite> are previously observed points,
and <cite>X_pending</cite> are points whose evaluation is pending. <cite>acq_function</cite> is a
BoTorch acquisition function crafted from these inputs. For additional
details on the arguments, see <cite>get_NEI</cite>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">acqf_optimizer</span><span class="p">(</span>
    <span class="n">acq_function</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">,</span>
    <span class="n">n</span><span class="p">,</span>
    <span class="n">inequality_constraints</span><span class="p">,</span>
    <span class="n">fixed_features</span><span class="p">,</span>
    <span class="n">rounding_func</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">candidates</span>
</pre></div>
</div>
<p>Here <cite>acq_function</cite> is a BoTorch <cite>AcquisitionFunction</cite>, <cite>bounds</cite> is a tensor
containing bounds on the parameters, <cite>n</cite> is the number of candidates to be
generated, <cite>inequality_constraints</cite> are inequality constraints on parameter
values, <cite>fixed_features</cite> specifies features that should be fixed during
generation, and <cite>rounding_func</cite> is a callback that rounds an optimization
result appropriately. <cite>candidates</cite> is a tensor of generated candidates.
For additional details on the arguments, see <cite>scipy_optimizer</cite>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">best_point_recommender</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">,</span>
    <span class="n">objective_weights</span><span class="p">,</span>
    <span class="n">outcome_constraints</span><span class="p">,</span>
    <span class="n">linear_constraints</span><span class="p">,</span>
    <span class="n">fixed_features</span><span class="p">,</span>
    <span class="n">model_gen_options</span><span class="p">,</span>
    <span class="n">target_fidelities</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">candidates</span>
</pre></div>
</div>
<p>Here <cite>model</cite> is a TorchModel, <cite>bounds</cite> is a list of tuples containing bounds
on the parameters, <cite>objective_weights</cite> is a tensor of weights for the model outputs,
<cite>outcome_constraints</cite> is a tuple of tensors describing the (linear) outcome
constraints, <cite>linear_constraints</cite> is a tuple of tensors describing constraints
on the design, <cite>fixed_features</cite> specifies features that should be fixed during
generation, <cite>model_gen_options</cite> is a config dictionary that can contain
model-specific options, and <cite>target_fidelities</cite> is a map from fidelity feature
column indices to their respective target fidelities, used for multi-fidelity
optimization problems. % TODO: refer to an example.</p>
<dl class="attribute">
<dt id="ax.models.torch.botorch.BotorchModel.Xs">
<code class="sig-name descname">Xs</code><em class="property">: List[Tensor]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel.Xs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch.BotorchModel.Ys">
<code class="sig-name descname">Ys</code><em class="property">: List[Tensor]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel.Ys" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch.BotorchModel.Yvars">
<code class="sig-name descname">Yvars</code><em class="property">: List[Tensor]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel.Yvars" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch.BotorchModel.best_point">
<code class="sig-name descname">best_point</code><span class="sig-paren">(</span><em class="sig-param">bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Optional[torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch.html#BotorchModel.best_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel.best_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Identify the current best point, satisfying the constraints in the same
format as to gen.</p>
<p>Return None if no such point can be identified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value in the best point.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>d-tensor of the best point.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch.BotorchModel.cross_validate">
<code class="sig-name descname">cross_validate</code><span class="sig-paren">(</span><em class="sig-param">Xs_train: List[torch.Tensor], Ys_train: List[torch.Tensor], Yvars_train: List[torch.Tensor], X_test: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch.html#BotorchModel.cross_validate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel.cross_validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Do cross validation with the given training and test sets.</p>
<p>Training set is given in the same format as to fit. Test set is given
in the same format as to predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs_train</strong> – A list of m (k_i x d) feature tensors X. Number of rows
k_i can vary from i=1,…,m.</p></li>
<li><p><strong>Ys_train</strong> – The corresponding list of m (k_i x 1) outcome tensors Y,
for each outcome.</p></li>
<li><p><strong>Yvars_train</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>X_test</strong> – (j x d) tensor of the j points at which to make predictions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) tensor of outcome predictions at X.</p></li>
<li><p>(j x m x m) tensor of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch.BotorchModel.device">
<code class="sig-name descname">device</code><em class="property">: Optional[torch.device]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel.device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch.BotorchModel.dtype">
<code class="sig-name descname">dtype</code><em class="property">: Optional[torch.dtype]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch.BotorchModel.feature_importances">
<code class="sig-name descname">feature_importances</code><span class="sig-paren">(</span><span class="sig-paren">)</span> → numpy.ndarray<a class="reference internal" href="_modules/ax/models/torch/botorch.html#BotorchModel.feature_importances"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel.feature_importances" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch.BotorchModel.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], bounds: List[Tuple[float, float]], task_features: List[int], feature_names: List[str], metric_names: List[str], fidelity_features: List[int], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/botorch.html#BotorchModel.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to m outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – A list of m (k_i x d) feature tensors X. Number of rows k_i can
vary from i=1,…,m.</p></li>
<li><p><strong>Ys</strong> – The corresponding list of m (k_i x 1) outcome tensors Y, for
each outcome.</p></li>
<li><p><strong>Yvars</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>bounds</strong> – A list of d (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>task_features</strong> – Columns of X that take integer values and should be
treated as task parameters.</p></li>
<li><p><strong>feature_names</strong> – Names of each column of X.</p></li>
<li><p><strong>metric_names</strong> – Names of each outcome Y in Ys.</p></li>
<li><p><strong>fidelity_features</strong> – Columns of X that should be treated as fidelity
parameters.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch.BotorchModel.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, pending_observations: Optional[List[torch.Tensor]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor, Dict[str, Any], Optional[List[Optional[Dict[str, Any]]]]]<a class="reference internal" href="_modules/ax/models/torch/botorch.html#BotorchModel.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>pending_observations</strong> – A list of m (k_i x d) feature tensors X
for m outcomes and k_i pending observations for outcome i.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (i.e., according to <cite>round-trip</cite> transformations).</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>4-element tuple containing</p>
<ul class="simple">
<li><p>(n x d) tensor of generated points.</p></li>
<li><p>n-tensor of weights for each point.</p></li>
<li><p>Generation metadata</p></li>
<li><dl class="simple">
<dt>Dictionary of model-specific metadata for the given</dt><dd><p>generation candidates</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch.BotorchModel.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch.html#BotorchModel.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – (j x d) tensor of the j points at which to make predictions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) tensor of outcome predictions at X.</p></li>
<li><p>(j x m x m) tensor of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch.BotorchModel.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/botorch.html#BotorchModel.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch.BotorchModel.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the model.</p>
<p>Updating the model requires both existing and additional data.
The data passed into this method will become the new training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>Ys</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>Yvars</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch.get_rounding_func">
<code class="sig-prename descclassname">ax.models.torch.botorch.</code><code class="sig-name descname">get_rounding_func</code><span class="sig-paren">(</span><em class="sig-param">rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]]</em><span class="sig-paren">)</span> → Optional[Callable[[torch.Tensor], torch.Tensor]]<a class="reference internal" href="_modules/ax/models/torch/botorch.html#get_rounding_func"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch.get_rounding_func" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_defaults">
<span id="ax-models-torch-botorch-defaults-module"></span><h3>ax.models.torch.botorch_defaults module<a class="headerlink" href="#module-ax.models.torch.botorch_defaults" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="ax.models.torch.botorch_defaults.get_NEI">
<code class="sig-prename descclassname">ax.models.torch.botorch_defaults.</code><code class="sig-name descname">get_NEI</code><span class="sig-paren">(</span><em class="sig-param">model: botorch.models.model.Model</em>, <em class="sig-param">objective_weights: torch.Tensor</em>, <em class="sig-param">outcome_constraints: Optional[Tuple[torch.Tensor</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">X_observed: Optional[torch.Tensor] = None</em>, <em class="sig-param">X_pending: Optional[torch.Tensor] = None</em>, <em class="sig-param">**kwargs: Any</em><span class="sig-paren">)</span> → botorch.acquisition.acquisition.AcquisitionFunction<a class="reference internal" href="_modules/ax/models/torch/botorch_defaults.html#get_NEI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_defaults.get_NEI" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a qNoisyExpectedImprovement acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The underlying model which the acqusition function uses
to estimate acquisition values of candidates.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>X_observed</strong> – A tensor containing points observed for all objective
outcomes and outcomes that appear in the outcome constraints (if
there are any).</p></li>
<li><p><strong>X_pending</strong> – A tensor containing points whose evaluation is pending (i.e.
that have been submitted for evaluation) present for all objective
outcomes and outcomes that appear in the outcome constraints (if
there are any).</p></li>
<li><p><strong>mc_samples</strong> – The number of MC samples to use (default: 512).</p></li>
<li><p><strong>qmc</strong> – If True, use qMC instead of MC (default: True).</p></li>
<li><p><strong>prune_baseline</strong> – If True, prune the baseline points for NEI (default: True).</p></li>
<li><p><strong>chebyshev_scalarization</strong> – Use augmented Chebyshev scalarization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The instantiated acquisition function.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>qNoisyExpectedImprovement</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_defaults.get_and_fit_model">
<code class="sig-prename descclassname">ax.models.torch.botorch_defaults.</code><code class="sig-name descname">get_and_fit_model</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], task_features: List[int], fidelity_features: List[int], metric_names: List[str], state_dict: Optional[Dict[str, torch.Tensor]] = None, refit_model: bool = True, use_input_warping: bool = False, **kwargs: Any</em><span class="sig-paren">)</span> → botorch.models.gpytorch.GPyTorchModel<a class="reference internal" href="_modules/ax/models/torch/botorch_defaults.html#get_and_fit_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_defaults.get_and_fit_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates and fits a botorch GPyTorchModel using the given data.
N.B. Currently, the logic for choosing ModelListGP vs other models is handled
using if-else statements in lines 96-137. In the future, this logic should be
taken care of by modular botorch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – List of X data, one tensor per outcome.</p></li>
<li><p><strong>Ys</strong> – List of Y data, one tensor per outcome.</p></li>
<li><p><strong>Yvars</strong> – List of observed variance of Ys.</p></li>
<li><p><strong>task_features</strong> – List of columns of X that are tasks.</p></li>
<li><p><strong>fidelity_features</strong> – List of columns of X that are fidelity parameters.</p></li>
<li><p><strong>metric_names</strong> – Names of each outcome Y in Ys.</p></li>
<li><p><strong>state_dict</strong> – If provided, will set model parameters to this state
dictionary. Otherwise, will fit the model.</p></li>
<li><p><strong>refit_model</strong> – Flag for refitting model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A fitted GPyTorchModel.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_defaults.get_warping_transform">
<code class="sig-prename descclassname">ax.models.torch.botorch_defaults.</code><code class="sig-name descname">get_warping_transform</code><span class="sig-paren">(</span><em class="sig-param">d: int</em>, <em class="sig-param">task_feature: Optional[int] = None</em><span class="sig-paren">)</span> → botorch.models.transforms.input.Warp<a class="reference internal" href="_modules/ax/models/torch/botorch_defaults.html#get_warping_transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_defaults.get_warping_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct input warping transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d</strong> – The dimension of the input, including task features</p></li>
<li><p><strong>task_feature</strong> – the index of the task feature</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The input warping transform.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_defaults.recommend_best_observed_point">
<code class="sig-prename descclassname">ax.models.torch.botorch_defaults.</code><code class="sig-name descname">recommend_best_observed_point</code><span class="sig-paren">(</span><em class="sig-param">model: ax.models.torch_base.TorchModel, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Optional[torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_defaults.html#recommend_best_observed_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_defaults.recommend_best_observed_point" title="Permalink to this definition">¶</a></dt>
<dd><p>A wrapper around <cite>ax.models.model_utils.best_observed_point</cite> for TorchModel
that recommends a best point from previously observed points using either a
“max_utility” or “feasible_threshold” strategy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – A TorchModel.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value in the best point.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A d-array of the best point, or None if no feasible point was observed.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_defaults.recommend_best_out_of_sample_point">
<code class="sig-prename descclassname">ax.models.torch.botorch_defaults.</code><code class="sig-name descname">recommend_best_out_of_sample_point</code><span class="sig-paren">(</span><em class="sig-param">model: ax.models.torch_base.TorchModel, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Optional[torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_defaults.html#recommend_best_out_of_sample_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_defaults.recommend_best_out_of_sample_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Identify the current best point by optimizing the posterior mean of the model.
This is “out-of-sample” because it considers un-observed designs as well.</p>
<p>Return None if no such point can be identified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – A TorchModel.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value in the best point.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A d-array of the best point, or None if no feasible point exists.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_defaults.scipy_optimizer">
<code class="sig-prename descclassname">ax.models.torch.botorch_defaults.</code><code class="sig-name descname">scipy_optimizer</code><span class="sig-paren">(</span><em class="sig-param">acq_function: botorch.acquisition.acquisition.AcquisitionFunction, bounds: torch.Tensor, n: int, inequality_constraints: Optional[List[Tuple[torch.Tensor, torch.Tensor, float]]] = None, fixed_features: Optional[Dict[int, float]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, **kwargs: Any</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_defaults.html#scipy_optimizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_defaults.scipy_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Optimizer using scipy’s minimize module on a numpy-adpator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> – A botorch AcquisitionFunction.</p></li>
<li><p><strong>bounds</strong> – A <cite>2 x d</cite>-dim tensor, where <cite>bounds[0]</cite> (<cite>bounds[1]</cite>) are the
lower (upper) bounds of the feasible hyperrectangle.</p></li>
<li><p><strong>n</strong> – The number of candidates to generate.</p></li>
<li><p><strong>constraints</strong> (<em>inequality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that should
be fixed to a particular value during generation.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (i.e., according to <cite>round-trip</cite> transformations).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>A <cite>n x d</cite>-dim tensor of generated candidates.</p></li>
<li><p>In the case of joint optimization, a scalar tensor containing
the joint acquisition value of the <cite>n</cite> points. In the case of
sequential optimization, a <cite>n</cite>-dim tensor of conditional acquisition
values, where <cite>i</cite>-th element is the expected acquisition value
conditional on having observed candidates <cite>0,1,…,i-1</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_kg">
<span id="ax-models-torch-botorch-kg-module"></span><h3>ax.models.torch.botorch_kg module<a class="headerlink" href="#module-ax.models.torch.botorch_kg" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.botorch_kg.KnowledgeGradient">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_kg.</code><code class="sig-name descname">KnowledgeGradient</code><span class="sig-paren">(</span><em class="sig-param">cost_intercept: float = 1.0</em>, <em class="sig-param">linear_truncated: bool = True</em>, <em class="sig-param">use_input_warping: bool = False</em>, <em class="sig-param">**kwargs: Any</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_kg.html#KnowledgeGradient"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_kg.KnowledgeGradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch.BotorchModel" title="ax.models.torch.botorch.BotorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch.BotorchModel</span></code></a></p>
<p>The Knowledge Gradient with one shot optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cost_intercept</strong> – The cost intercept for the affine cost of the form
<cite>cost_intercept + n</cite>, where <cite>n</cite> is the number of generated points.
Only used for multi-fidelity optimzation (i.e., if fidelity_features
are present).</p></li>
<li><p><strong>linear_truncated</strong> – If <cite>False</cite>, use an alternate downsampling + exponential
decay Kernel instead of the default <cite>LinearTruncatedFidelityKernel</cite>
(only relevant for multi-fidelity optimization).</p></li>
<li><p><strong>kwargs</strong> – Model-specific kwargs.</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_kg.KnowledgeGradient.Xs">
<code class="sig-name descname">Xs</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_kg.KnowledgeGradient.Xs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_kg.KnowledgeGradient.Ys">
<code class="sig-name descname">Ys</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_kg.KnowledgeGradient.Ys" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_kg.KnowledgeGradient.Yvars">
<code class="sig-name descname">Yvars</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_kg.KnowledgeGradient.Yvars" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_kg.KnowledgeGradient.device">
<code class="sig-name descname">device</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_kg.KnowledgeGradient.device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_kg.KnowledgeGradient.dtype">
<code class="sig-name descname">dtype</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_kg.KnowledgeGradient.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_kg.KnowledgeGradient.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List, objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, pending_observations: Optional[List[torch.Tensor]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor, Dict[str, Any], Optional[List[Optional[Dict[str, Any]]]]]<a class="reference internal" href="_modules/ax/models/torch/botorch_kg.html#KnowledgeGradient.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_kg.KnowledgeGradient.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>pending_observations</strong> – A list of m (k_i x d) feature tensors X
for m outcomes and k_i pending observations for outcome i.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (i.e., according to <cite>round-trip</cite> transformations).</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>3-element tuple containing</p>
<ul class="simple">
<li><p>(n x d) tensor of generated points.</p></li>
<li><p>n-tensor of weights for each point.</p></li>
<li><dl class="simple">
<dt>Dictionary of model-specific metadata for the given</dt><dd><p>generation candidates.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_mes">
<span id="ax-models-torch-botorch-mes-module"></span><h3>ax.models.torch.botorch_mes module<a class="headerlink" href="#module-ax.models.torch.botorch_mes" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.botorch_mes.MaxValueEntropySearch">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_mes.</code><code class="sig-name descname">MaxValueEntropySearch</code><span class="sig-paren">(</span><em class="sig-param">cost_intercept: float = 1.0</em>, <em class="sig-param">linear_truncated: bool = True</em>, <em class="sig-param">use_input_warping: bool = False</em>, <em class="sig-param">**kwargs: Any</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_mes.html#MaxValueEntropySearch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_mes.MaxValueEntropySearch" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch.BotorchModel" title="ax.models.torch.botorch.BotorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch.BotorchModel</span></code></a></p>
<p>Max-value entropy search.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cost_intercept</strong> – The cost intercept for the affine cost of the form
<cite>cost_intercept + n</cite>, where <cite>n</cite> is the number of generated points.
Only used for multi-fidelity optimzation (i.e., if fidelity_features
are present).</p></li>
<li><p><strong>linear_truncated</strong> – If <cite>False</cite>, use an alternate downsampling + exponential
decay Kernel instead of the default <cite>LinearTruncatedFidelityKernel</cite>
(only relevant for multi-fidelity optimization).</p></li>
<li><p><strong>kwargs</strong> – Model-specific kwargs.</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_mes.MaxValueEntropySearch.Xs">
<code class="sig-name descname">Xs</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_mes.MaxValueEntropySearch.Xs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_mes.MaxValueEntropySearch.Ys">
<code class="sig-name descname">Ys</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_mes.MaxValueEntropySearch.Ys" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_mes.MaxValueEntropySearch.Yvars">
<code class="sig-name descname">Yvars</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_mes.MaxValueEntropySearch.Yvars" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_mes.MaxValueEntropySearch.device">
<code class="sig-name descname">device</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_mes.MaxValueEntropySearch.device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_mes.MaxValueEntropySearch.dtype">
<code class="sig-name descname">dtype</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_mes.MaxValueEntropySearch.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_mes.MaxValueEntropySearch.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List, objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, pending_observations: Optional[List[torch.Tensor]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor, Dict[str, Any], List[Optional[Dict[str, Any]]]]<a class="reference internal" href="_modules/ax/models/torch/botorch_mes.html#MaxValueEntropySearch.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_mes.MaxValueEntropySearch.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>pending_observations</strong> – A list of m (k_i x d) feature tensors X
for m outcomes and k_i pending observations for outcome i.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (i.e., according to <cite>round-trip</cite> transformations).</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>4-element tuple containing</p>
<ul class="simple">
<li><p>(n x d) tensor of generated points.</p></li>
<li><p>n-tensor of weights for each point.</p></li>
<li><p>Generation metadata</p></li>
<li><dl class="simple">
<dt>Dictionary of model-specific metadata for the given</dt><dd><p>generation candidates</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_moo">
<span id="ax-models-torch-botorch-moo-module"></span><h3>ax.models.torch.botorch_moo module<a class="headerlink" href="#module-ax.models.torch.botorch_moo" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.botorch_moo.MultiObjectiveBotorchModel">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_moo.</code><code class="sig-name descname">MultiObjectiveBotorchModel</code><span class="sig-paren">(</span><em class="sig-param">model_constructor: Callable[[List[torch.Tensor], List[torch.Tensor], List[torch.Tensor], List[int], List[int], List[str], Optional[Dict[str, torch.Tensor]], Any], botorch.models.model.Model] = &lt;function get_and_fit_model&gt;, model_predictor: Callable[[botorch.models.model.Model, torch.Tensor], Tuple[torch.Tensor, torch.Tensor]] = &lt;function predict_from_model&gt;, acqf_constructor: Callable[[botorch.models.model.Model, torch.Tensor, Optional[Tuple[torch.Tensor, torch.Tensor]], Optional[torch.Tensor], Optional[torch.Tensor], Any], botorch.acquisition.acquisition.AcquisitionFunction] = &lt;function get_EHVI&gt;, acqf_optimizer: Callable[[botorch.acquisition.acquisition.AcquisitionFunction, torch.Tensor, int, Optional[List[Tuple[torch.Tensor, torch.Tensor, float]]], Optional[Dict[int, float]], Optional[Callable[[torch.Tensor], torch.Tensor]], Any], Tuple[torch.Tensor, torch.Tensor]] = &lt;function scipy_optimizer&gt;, best_point_recommender: Callable[[ax.models.torch_base.TorchModel, List[Tuple[float, float]], torch.Tensor, Optional[Tuple[torch.Tensor, torch.Tensor]], Optional[Tuple[torch.Tensor, torch.Tensor]], Optional[Dict[int, float]], Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]], Optional[Dict[int, float]]], Optional[torch.Tensor]] = &lt;function recommend_best_observed_point&gt;, frontier_evaluator: Callable[[ax.models.torch_base.TorchModel, torch.Tensor, Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor], Optional[Tuple[torch.Tensor, torch.Tensor]]], Tuple[torch.Tensor, torch.Tensor]] = &lt;function pareto_frontier_evaluator&gt;, refit_on_cv: bool = False, refit_on_update: bool = True, warm_start_refitting: bool = False, use_input_warping: bool = False, **kwargs: Any</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_moo.html#MultiObjectiveBotorchModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_moo.MultiObjectiveBotorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch.BotorchModel" title="ax.models.torch.botorch.BotorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch.BotorchModel</span></code></a></p>
<p>Customizable multi-objective model.</p>
<p>By default, this uses an Expected Hypervolume Improvment function to find the
pareto frontier of a function with multiple outcomes. This behavior
can be modified by providing custom implementations of the following
components:</p>
<ul class="simple">
<li><p>a <cite>model_constructor</cite> that instantiates and fits a model on data</p></li>
<li><p>a <cite>model_predictor</cite> that predicts outcomes using the fitted model</p></li>
<li><p>a <cite>acqf_constructor</cite> that creates an acquisition function from a fitted model</p></li>
<li><p>a <cite>acqf_optimizer</cite> that optimizes the acquisition function</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_constructor</strong> – A callable that instantiates and fits a model on data,
with signature as described below.</p></li>
<li><p><strong>model_predictor</strong> – A callable that predicts using the fitted model, with
signature as described below.</p></li>
<li><p><strong>acqf_constructor</strong> – A callable that creates an acquisition function from a
fitted model, with signature as described below.</p></li>
<li><p><strong>acqf_optimizer</strong> – A callable that optimizes an acquisition
function, with signature as described below.</p></li>
</ul>
</dd>
</dl>
<p>Call signatures:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_constructor</span><span class="p">(</span>
    <span class="n">Xs</span><span class="p">,</span>
    <span class="n">Ys</span><span class="p">,</span>
    <span class="n">Yvars</span><span class="p">,</span>
    <span class="n">task_features</span><span class="p">,</span>
    <span class="n">fidelity_features</span><span class="p">,</span>
    <span class="n">metric_names</span><span class="p">,</span>
    <span class="n">state_dict</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">model</span>
</pre></div>
</div>
<p>Here <cite>Xs</cite>, <cite>Ys</cite>, <cite>Yvars</cite> are lists of tensors (one element per outcome),
<cite>task_features</cite> identifies columns of Xs that should be modeled as a task,
<cite>fidelity_features</cite> is a list of ints that specify the positions of fidelity
parameters in ‘Xs’, <cite>metric_names</cite> provides the names of each <cite>Y</cite> in <cite>Ys</cite>,
<cite>state_dict</cite> is a pytorch module state dict, and <cite>model</cite> is a BoTorch <cite>Model</cite>.
Optional kwargs are being passed through from the <cite>BotorchModel</cite> constructor.
This callable is assumed to return a fitted BoTorch model that has the same
dtype and lives on the same device as the input tensors.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_predictor</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">[</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">]</span>
</pre></div>
</div>
<p>Here <cite>model</cite> is a fitted botorch model, <cite>X</cite> is a tensor of candidate points,
and <cite>mean</cite> and <cite>cov</cite> are the posterior mean and covariance, respectively.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">acqf_constructor</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">objective_weights</span><span class="p">,</span>
    <span class="n">outcome_constraints</span><span class="p">,</span>
    <span class="n">X_observed</span><span class="p">,</span>
    <span class="n">X_pending</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">acq_function</span>
</pre></div>
</div>
<p>Here <cite>model</cite> is a botorch <cite>Model</cite>, <cite>objective_weights</cite> is a tensor of weights
for the model outputs, <cite>outcome_constraints</cite> is a tuple of tensors describing
the (linear) outcome constraints, <cite>X_observed</cite> are previously observed points,
and <cite>X_pending</cite> are points whose evaluation is pending. <cite>acq_function</cite> is a
BoTorch acquisition function crafted from these inputs. For additional
details on the arguments, see <cite>get_NEI</cite>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">acqf_optimizer</span><span class="p">(</span>
    <span class="n">acq_function</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">,</span>
    <span class="n">n</span><span class="p">,</span>
    <span class="n">inequality_constraints</span><span class="p">,</span>
    <span class="n">fixed_features</span><span class="p">,</span>
    <span class="n">rounding_func</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">candidates</span>
</pre></div>
</div>
<p>Here <cite>acq_function</cite> is a BoTorch <cite>AcquisitionFunction</cite>, <cite>bounds</cite> is a tensor
containing bounds on the parameters, <cite>n</cite> is the number of candidates to be
generated, <cite>inequality_constraints</cite> are inequality constraints on parameter
values, <cite>fixed_features</cite> specifies features that should be fixed during
generation, and <cite>rounding_func</cite> is a callback that rounds an optimization
result appropriately. <cite>candidates</cite> is a tensor of generated candidates.
For additional details on the arguments, see <cite>scipy_optimizer</cite>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">frontier_evaluator</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">objective_weights</span><span class="p">,</span>
    <span class="n">objective_thresholds</span><span class="p">,</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">Y</span><span class="p">,</span>
    <span class="n">Yvar</span><span class="p">,</span>
    <span class="n">outcome_constraints</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Here <cite>model</cite> is a botorch <cite>Model</cite>, <cite>objective_thresholds</cite> is used in hypervolume
evaluations, <cite>objective_weights</cite> is a tensor of weights applied to the  objectives
(sign represents direction), <cite>X</cite>, <cite>Y</cite>, <cite>Yvar</cite> are tensors, <cite>outcome_constraints</cite> is
a tuple of tensors describing the (linear) outcome constraints.</p>
<dl class="attribute">
<dt id="ax.models.torch.botorch_moo.MultiObjectiveBotorchModel.Xs">
<code class="sig-name descname">Xs</code><em class="property">: List[Tensor]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_moo.MultiObjectiveBotorchModel.Xs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_moo.MultiObjectiveBotorchModel.Ys">
<code class="sig-name descname">Ys</code><em class="property">: List[Tensor]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_moo.MultiObjectiveBotorchModel.Ys" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_moo.MultiObjectiveBotorchModel.Yvars">
<code class="sig-name descname">Yvars</code><em class="property">: List[Tensor]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_moo.MultiObjectiveBotorchModel.Yvars" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_moo.MultiObjectiveBotorchModel.device">
<code class="sig-name descname">device</code><em class="property">: Optional[torch.device]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_moo.MultiObjectiveBotorchModel.device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_moo.MultiObjectiveBotorchModel.dtype">
<code class="sig-name descname">dtype</code><em class="property">: Optional[torch.dtype]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_moo.MultiObjectiveBotorchModel.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_moo.MultiObjectiveBotorchModel.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, objective_thresholds: Optional[torch.Tensor] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, pending_observations: Optional[List[torch.Tensor]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor, Dict[str, Any], Optional[List[Optional[Dict[str, Any]]]]]<a class="reference internal" href="_modules/ax/models/torch/botorch_moo.html#MultiObjectiveBotorchModel.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_moo.MultiObjectiveBotorchModel.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>pending_observations</strong> – A list of m (k_i x d) feature tensors X
for m outcomes and k_i pending observations for outcome i.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (i.e., according to <cite>round-trip</cite> transformations).</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>4-element tuple containing</p>
<ul class="simple">
<li><p>(n x d) tensor of generated points.</p></li>
<li><p>n-tensor of weights for each point.</p></li>
<li><p>Generation metadata</p></li>
<li><dl class="simple">
<dt>Dictionary of model-specific metadata for the given</dt><dd><p>generation candidates</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_moo_defaults">
<span id="ax-models-torch-botorch-moo-defaults-module"></span><h3>ax.models.torch.botorch_moo_defaults module<a class="headerlink" href="#module-ax.models.torch.botorch_moo_defaults" title="Permalink to this headline">¶</a></h3>
<p>References</p>
<dl class="citation">
<dt class="label" id="daulton2020qehvi"><span class="brackets"><a class="fn-backref" href="#id1">Daulton2020qehvi</a></span></dt>
<dd><p>S. Daulton, M. Balandat, and E. Bakshy. Differentiable Expected Hypervolume
Improvement for Parallel Multi-Objective Bayesian Optimization. Advances in Neural
Information Processing Systems 33, 2020.</p>
</dd>
</dl>
<dl class="function">
<dt id="ax.models.torch.botorch_moo_defaults.get_EHVI">
<code class="sig-prename descclassname">ax.models.torch.botorch_moo_defaults.</code><code class="sig-name descname">get_EHVI</code><span class="sig-paren">(</span><em class="sig-param">model: botorch.models.model.Model</em>, <em class="sig-param">objective_weights: torch.Tensor</em>, <em class="sig-param">objective_thresholds: torch.Tensor</em>, <em class="sig-param">outcome_constraints: Optional[Tuple[torch.Tensor</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">X_observed: Optional[torch.Tensor] = None</em>, <em class="sig-param">X_pending: Optional[torch.Tensor] = None</em>, <em class="sig-param">**kwargs: Any</em><span class="sig-paren">)</span> → botorch.acquisition.acquisition.AcquisitionFunction<a class="reference internal" href="_modules/ax/models/torch/botorch_moo_defaults.html#get_EHVI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_moo_defaults.get_EHVI" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a qExpectedHyperVolumeImprovement acquisition function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The underlying model which the acqusition function uses
to estimate acquisition values of candidates.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>objective_thresholds</strong> – A tensor containing thresholds forming a reference point
from which to calculate pareto frontier hypervolume. Points that do not
dominate the objective_thresholds contribute nothing to hypervolume.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>X_observed</strong> – A tensor containing points observed for all objective
outcomes and outcomes that appear in the outcome constraints (if
there are any).</p></li>
<li><p><strong>X_pending</strong> – A tensor containing points whose evaluation is pending (i.e.
that have been submitted for evaluation) present for all objective
outcomes and outcomes that appear in the outcome constraints (if
there are any).</p></li>
<li><p><strong>mc_samples</strong> – The number of MC samples to use (default: 512).</p></li>
<li><p><strong>qmc</strong> – If True, use qMC instead of MC (default: True).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The instantiated acquisition function.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>qExpectedHypervolumeImprovement</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_moo_defaults.get_default_frontier_evaluator">
<code class="sig-prename descclassname">ax.models.torch.botorch_moo_defaults.</code><code class="sig-name descname">get_default_frontier_evaluator</code><span class="sig-paren">(</span><span class="sig-paren">)</span> → Callable[[ax.models.torch_base.TorchModel, torch.Tensor, Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor], Optional[Tuple[torch.Tensor, torch.Tensor]]], Tuple[torch.Tensor, torch.Tensor]]<a class="reference internal" href="_modules/ax/models/torch/botorch_moo_defaults.html#get_default_frontier_evaluator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_moo_defaults.get_default_frontier_evaluator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_moo_defaults.get_default_partitioning_alpha">
<code class="sig-prename descclassname">ax.models.torch.botorch_moo_defaults.</code><code class="sig-name descname">get_default_partitioning_alpha</code><span class="sig-paren">(</span><em class="sig-param">num_objectives: int</em><span class="sig-paren">)</span> → float<a class="reference internal" href="_modules/ax/models/torch/botorch_moo_defaults.html#get_default_partitioning_alpha"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_moo_defaults.get_default_partitioning_alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Adaptively selects a reasonable partitioning based on the number of objectives.</p>
<p>This strategy is derived from the results in <a class="reference internal" href="#daulton2020qehvi" id="id1"><span>[Daulton2020qehvi]</span></a>, which suggest
that this heuristic provides a reasonable trade-off between the closed-loop
performance and the wall time required for the partitioning.</p>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_moo_defaults.get_weighted_mc_objective_and_objective_thresholds">
<code class="sig-prename descclassname">ax.models.torch.botorch_moo_defaults.</code><code class="sig-name descname">get_weighted_mc_objective_and_objective_thresholds</code><span class="sig-paren">(</span><em class="sig-param">objective_weights: torch.Tensor</em>, <em class="sig-param">objective_thresholds: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[botorch.acquisition.multi_objective.objective.WeightedMCMultiOutputObjective, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_moo_defaults.html#get_weighted_mc_objective_and_objective_thresholds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_moo_defaults.get_weighted_mc_objective_and_objective_thresholds" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct weighted objective and apply the weights to objective thresholds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>objective_thresholds</strong> – A tensor containing thresholds forming a reference point
from which to calculate pareto frontier hypervolume. Points that do not
dominate the objective_thresholds contribute nothing to hypervolume.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The objective</p></li>
<li><p>The objective thresholds</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-element tuple with the objective and objective thresholds</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_moo_defaults.pareto_frontier_evaluator">
<code class="sig-prename descclassname">ax.models.torch.botorch_moo_defaults.</code><code class="sig-name descname">pareto_frontier_evaluator</code><span class="sig-paren">(</span><em class="sig-param">model: ax.models.torch_base.TorchModel</em>, <em class="sig-param">objective_weights: torch.Tensor</em>, <em class="sig-param">objective_thresholds: Optional[torch.Tensor] = None</em>, <em class="sig-param">X: Optional[torch.Tensor] = None</em>, <em class="sig-param">Y: Optional[torch.Tensor] = None</em>, <em class="sig-param">Yvar: Optional[torch.Tensor] = None</em>, <em class="sig-param">outcome_constraints: Optional[Tuple[torch.Tensor</em>, <em class="sig-param">torch.Tensor]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_moo_defaults.html#pareto_frontier_evaluator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_moo_defaults.pareto_frontier_evaluator" title="Permalink to this definition">¶</a></dt>
<dd><p>Return outcomes predicted to lie on a pareto frontier.</p>
<p>Given a model and a points to evaluate use the model to predict which points
lie on the pareto frontier.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Model used to predict outcomes.</p></li>
<li><p><strong>objective_weights</strong> – A <cite>m</cite> tensor of values indicating the weight to put
on different outcomes. For pareto frontiers only the sign matters.</p></li>
<li><p><strong>objective_thresholds</strong> – A tensor containing thresholds forming a reference point
from which to calculate pareto frontier hypervolume. Points that do not
dominate the objective_thresholds contribute nothing to hypervolume.</p></li>
<li><p><strong>X</strong> – A <cite>n x d</cite> tensor of features to evaluate.</p></li>
<li><p><strong>Y</strong> – A <cite>n x m</cite> tensor of outcomes to use instead of predictions.</p></li>
<li><p><strong>Yvar</strong> – A <cite>n x m</cite> tensor of input variances (NaN if unobserved).</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><dl class="simple">
<dt>A <cite>j x m</cite> tensor of outcome on the pareto frontier. j is the number</dt><dd><p>of frontier points.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>A <cite>j x m x m</cite> tensor of predictive covariances.</dt><dd><p>cov[j, m1, m2] is Cov[m1@j, m2@j].</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_moo_defaults.scipy_optimizer_list">
<code class="sig-prename descclassname">ax.models.torch.botorch_moo_defaults.</code><code class="sig-name descname">scipy_optimizer_list</code><span class="sig-paren">(</span><em class="sig-param">acq_function_list: List[botorch.acquisition.acquisition.AcquisitionFunction], bounds: torch.Tensor, inequality_constraints: Optional[List[Tuple[torch.Tensor, torch.Tensor, float]]] = None, fixed_features: Optional[Dict[int, float]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, **kwargs: Any</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_moo_defaults.html#scipy_optimizer_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_moo_defaults.scipy_optimizer_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Sequential optimizer using scipy’s minimize module on a numpy-adaptor.</p>
<p>The ith acquisition in the sequence uses the ith given acquisition_function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function_list</strong> – A list of botorch AcquisitionFunctions,
optimized sequentially.</p></li>
<li><p><strong>bounds</strong> – A <cite>2 x d</cite>-dim tensor, where <cite>bounds[0]</cite> (<cite>bounds[1]</cite>) are the
lower (upper) bounds of the feasible hyperrectangle.</p></li>
<li><p><strong>n</strong> – The number of candidates to generate.</p></li>
<li><p><strong>constraints</strong> (<em>inequality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that should
be fixed to a particular value during generation.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (i.e., according to <cite>round-trip</cite> transformations).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>A <cite>n x d</cite>-dim tensor of generated candidates.</p></li>
<li><p>A <cite>n</cite>-dim tensor of conditional acquisition
values, where <cite>i</cite>-th element is the expected acquisition value
conditional on having observed candidates <cite>0,1,…,i-1</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_modular.acquisition">
<span id="ax-models-torch-botorch-modular-acquisition-module"></span><h3>ax.models.torch.botorch_modular.acquisition module<a class="headerlink" href="#module-ax.models.torch.botorch_modular.acquisition" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.botorch_modular.acquisition.Acquisition">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_modular.acquisition.</code><code class="sig-name descname">Acquisition</code><span class="sig-paren">(</span><em class="sig-param">surrogate: ax.models.torch.botorch_modular.surrogate.Surrogate, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, botorch_acqf_class: Optional[Type[botorch.acquisition.acquisition.AcquisitionFunction]] = None, options: Optional[Dict[str, Any]] = None, pending_observations: Optional[List[torch.Tensor]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_modular/acquisition.html#Acquisition"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.acquisition.Acquisition" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="utils.html#ax.utils.common.base.Base" title="ax.utils.common.base.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.utils.common.base.Base</span></code></a></p>
<p><strong>All classes in ‘botorch_modular’ directory are under
construction, incomplete, and should be treated as alpha
versions only.</strong></p>
<p>Ax wrapper for BoTorch <cite>AcquisitionFunction</cite>, subcomponent
of <cite>BoTorchModel</cite> and is not meant to be used outside of it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>surrogate</strong> – Surrogate model, with which this acquisition function
will be used.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X in
the training data of the surrogate model.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>botorch_acqf_class</strong> – Type of BoTorch <cite>AcquistitionFunction</cite> that
should be used. Subclasses of <cite>Acquisition</cite> often specify
these via <cite>default_botorch_acqf_class</cite> attribute, in which
case specifying one here is not required.</p></li>
<li><p><strong>options</strong> – Optional mapping of kwargs to the underlying <cite>Acquisition
Function</cite> in BoTorch.</p></li>
<li><p><strong>pending_observations</strong> – A list of tensors, each of which contains
points whose evaluation is pending (i.e. that have been
submitted for evaluation) for a given outcome. A list
of m (k_i x d) feature tensors X for m outcomes and k_i,
pending observations for outcome i.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>target_fidelities</strong> – Optional mapping from parameter name to its
target fidelity, applicable to fidelity parameters only.</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.acquisition.Acquisition.acqf">
<code class="sig-name descname">acqf</code><em class="property">: AcquisitionFunction</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.acquisition.Acquisition.acqf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.acquisition.Acquisition.best_point">
<code class="sig-name descname">best_point</code><span class="sig-paren">(</span><em class="sig-param">bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, target_fidelities: Optional[Dict[int, float]] = None, options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, float]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/acquisition.html#Acquisition.best_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.acquisition.Acquisition.best_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds the best observed point and the corresponding observed outcome
values.</p>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.acquisition.Acquisition.compute_model_dependencies">
<code class="sig-name descname">compute_model_dependencies</code><span class="sig-paren">(</span><em class="sig-param">surrogate: ax.models.torch.botorch_modular.surrogate.Surrogate, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, pending_observations: Optional[List[torch.Tensor]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, target_fidelities: Optional[Dict[int, float]] = None, options: Optional[Dict[str, Any]] = None</em><span class="sig-paren">)</span> → Dict[str, Any]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/acquisition.html#Acquisition.compute_model_dependencies"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.acquisition.Acquisition.compute_model_dependencies" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes inputs to acquisition function class based on the given
surrogate model.</p>
<p>NOTE: When subclassing <cite>Acquisition</cite> from a superclass where this
method returns a non-empty dictionary of kwargs to <cite>AcquisitionFunction</cite>,
call <cite>super().compute_model_dependencies</cite> and then update that
dictionary of options with the options for the subclass you are creating
(unless the superclass’ model dependencies should not be propagated to
the subclass). See <cite>MultiFidelityKnowledgeGradient.compute_model_dependencies</cite>
for an example.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>surrogate</strong> – The surrogate object containing the BoTorch <cite>Model</cite>,
with which this <cite>Acquisition</cite> is to be used.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X in
the training data of the surrogate model.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>pending_observations</strong> – A list of tensors, each of which contains
points whose evaluation is pending (i.e. that have been
submitted for evaluation) for a given outcome. A list
of m (k_i x d) feature tensors X for m outcomes and k_i,
pending observations for outcome i.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>target_fidelities</strong> – Optional mapping from parameter name to its
target fidelity, applicable to fidelity parameters only.</p></li>
<li><p><strong>options</strong> – The <cite>options</cite> kwarg dict, passed on initialization of
the <cite>Acquisition</cite> object.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Returns: A dictionary of surrogate model-dependent options, to be passed</dt><dd><p>as kwargs to BoTorch`AcquisitionFunction` constructor.</p>
</dd>
</dl>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.acquisition.Acquisition.default_botorch_acqf_class">
<code class="sig-name descname">default_botorch_acqf_class</code><em class="property">: Optional[Type[AcquisitionFunction]]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.acquisition.Acquisition.default_botorch_acqf_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.acquisition.Acquisition.evaluate">
<code class="sig-name descname">evaluate</code><span class="sig-paren">(</span><em class="sig-param">X: torch.Tensor</em><span class="sig-paren">)</span> → torch.Tensor<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/acquisition.html#Acquisition.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.acquisition.Acquisition.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the acquisition function on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – A <cite>batch_shape x q x d</cite>-dim Tensor of t-batches with <cite>q</cite> <cite>d</cite>-dim design
points each.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <cite>batch_shape’</cite>-dim Tensor of acquisition values at the given
design points <cite>X</cite>, where <cite>batch_shape’</cite> is the broadcasted batch shape of
model and input <cite>X</cite>.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.acquisition.Acquisition.optimize">
<code class="sig-name descname">optimize</code><span class="sig-paren">(</span><em class="sig-param">bounds: torch.Tensor, n: int, optimizer_class: Optional[ax.models.torch.botorch_modular.acquisition.Optimizer] = None, inequality_constraints: Optional[List[Tuple[torch.Tensor, torch.Tensor, float]]] = None, fixed_features: Optional[Dict[int, float]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, optimizer_options: Optional[Dict[str, Any]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/acquisition.html#Acquisition.optimize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.acquisition.Acquisition.optimize" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a set of candidates via multi-start optimization. Obtains
candidates and their associated acquisition function values.</p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.acquisition.Acquisition.surrogate">
<code class="sig-name descname">surrogate</code><em class="property">: Surrogate</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.acquisition.Acquisition.surrogate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="class">
<dt id="ax.models.torch.botorch_modular.acquisition.Optimizer">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_modular.acquisition.</code><code class="sig-name descname">Optimizer</code><a class="reference internal" href="_modules/ax/models/torch/botorch_modular/acquisition.html#Optimizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.acquisition.Optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_modular.kg">
<span id="ax-models-torch-botorch-modular-kg-module"></span><h3>ax.models.torch.botorch_modular.kg module<a class="headerlink" href="#module-ax.models.torch.botorch_modular.kg" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.botorch_modular.kg.KnowledgeGradient">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_modular.kg.</code><code class="sig-name descname">KnowledgeGradient</code><span class="sig-paren">(</span><em class="sig-param">surrogate: ax.models.torch.botorch_modular.surrogate.Surrogate, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, botorch_acqf_class: Optional[Type[botorch.acquisition.acquisition.AcquisitionFunction]] = None, options: Optional[Dict[str, Any]] = None, pending_observations: Optional[List[torch.Tensor]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_modular/kg.html#KnowledgeGradient"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.KnowledgeGradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch_modular.kg.OneShotAcquisition" title="ax.models.torch.botorch_modular.kg.OneShotAcquisition"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch_modular.kg.OneShotAcquisition</span></code></a></p>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.kg.KnowledgeGradient.acqf">
<code class="sig-name descname">acqf</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.KnowledgeGradient.acqf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.kg.KnowledgeGradient.default_botorch_acqf_class">
<code class="sig-name descname">default_botorch_acqf_class</code><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.KnowledgeGradient.default_botorch_acqf_class" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.acquisition.knowledge_gradient.qKnowledgeGradient</span></code></p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.kg.KnowledgeGradient.surrogate">
<code class="sig-name descname">surrogate</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.KnowledgeGradient.surrogate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="class">
<dt id="ax.models.torch.botorch_modular.kg.MultiFidelityKnowledgeGradient">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_modular.kg.</code><code class="sig-name descname">MultiFidelityKnowledgeGradient</code><span class="sig-paren">(</span><em class="sig-param">surrogate: ax.models.torch.botorch_modular.surrogate.Surrogate, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, botorch_acqf_class: Optional[Type[botorch.acquisition.acquisition.AcquisitionFunction]] = None, options: Optional[Dict[str, Any]] = None, pending_observations: Optional[List[torch.Tensor]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_modular/kg.html#MultiFidelityKnowledgeGradient"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.MultiFidelityKnowledgeGradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition" title="ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition</span></code></a>, <a class="reference internal" href="#ax.models.torch.botorch_modular.kg.KnowledgeGradient" title="ax.models.torch.botorch_modular.kg.KnowledgeGradient"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch_modular.kg.KnowledgeGradient</span></code></a></p>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.kg.MultiFidelityKnowledgeGradient.acqf">
<code class="sig-name descname">acqf</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.MultiFidelityKnowledgeGradient.acqf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.kg.MultiFidelityKnowledgeGradient.compute_model_dependencies">
<code class="sig-name descname">compute_model_dependencies</code><span class="sig-paren">(</span><em class="sig-param">surrogate: ax.models.torch.botorch_modular.surrogate.Surrogate, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, target_fidelities: Optional[Dict[int, float]] = None, pending_observations: Optional[List[torch.Tensor]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, options: Optional[Dict[str, Any]] = None</em><span class="sig-paren">)</span> → Dict[str, Any]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/kg.html#MultiFidelityKnowledgeGradient.compute_model_dependencies"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.MultiFidelityKnowledgeGradient.compute_model_dependencies" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes inputs to acquisition function class based on the given
surrogate model.</p>
<p>NOTE: When subclassing <cite>Acquisition</cite> from a superclass where this
method returns a non-empty dictionary of kwargs to <cite>AcquisitionFunction</cite>,
call <cite>super().compute_model_dependencies</cite> and then update that
dictionary of options with the options for the subclass you are creating
(unless the superclass’ model dependencies should not be propagated to
the subclass). See <cite>MultiFidelityKnowledgeGradient.compute_model_dependencies</cite>
for an example.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>surrogate</strong> – The surrogate object containing the BoTorch <cite>Model</cite>,
with which this <cite>Acquisition</cite> is to be used.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X in
the training data of the surrogate model.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>pending_observations</strong> – A list of tensors, each of which contains
points whose evaluation is pending (i.e. that have been
submitted for evaluation) for a given outcome. A list
of m (k_i x d) feature tensors X for m outcomes and k_i,
pending observations for outcome i.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>target_fidelities</strong> – Optional mapping from parameter name to its
target fidelity, applicable to fidelity parameters only.</p></li>
<li><p><strong>options</strong> – The <cite>options</cite> kwarg dict, passed on initialization of
the <cite>Acquisition</cite> object.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Returns: A dictionary of surrogate model-dependent options, to be passed</dt><dd><p>as kwargs to BoTorch`AcquisitionFunction` constructor.</p>
</dd>
</dl>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.kg.MultiFidelityKnowledgeGradient.default_botorch_acqf_class">
<code class="sig-name descname">default_botorch_acqf_class</code><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.MultiFidelityKnowledgeGradient.default_botorch_acqf_class" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.acquisition.knowledge_gradient.qMultiFidelityKnowledgeGradient</span></code></p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.kg.MultiFidelityKnowledgeGradient.surrogate">
<code class="sig-name descname">surrogate</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.MultiFidelityKnowledgeGradient.surrogate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="class">
<dt id="ax.models.torch.botorch_modular.kg.OneShotAcquisition">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_modular.kg.</code><code class="sig-name descname">OneShotAcquisition</code><span class="sig-paren">(</span><em class="sig-param">surrogate: ax.models.torch.botorch_modular.surrogate.Surrogate, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, botorch_acqf_class: Optional[Type[botorch.acquisition.acquisition.AcquisitionFunction]] = None, options: Optional[Dict[str, Any]] = None, pending_observations: Optional[List[torch.Tensor]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_modular/kg.html#OneShotAcquisition"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.OneShotAcquisition" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch_modular.acquisition.Acquisition" title="ax.models.torch.botorch_modular.acquisition.Acquisition"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch_modular.acquisition.Acquisition</span></code></a></p>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.kg.OneShotAcquisition.acqf">
<code class="sig-name descname">acqf</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.OneShotAcquisition.acqf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.kg.OneShotAcquisition.optimize">
<code class="sig-name descname">optimize</code><span class="sig-paren">(</span><em class="sig-param">bounds: torch.Tensor, n: int, optimizer_class: Optional[ax.models.torch.botorch_modular.acquisition.Optimizer] = None, inequality_constraints: Optional[List[Tuple[torch.Tensor, torch.Tensor, float]]] = None, fixed_features: Optional[Dict[int, float]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, optimizer_options: Optional[Dict[str, Any]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/kg.html#OneShotAcquisition.optimize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.OneShotAcquisition.optimize" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a set of candidates via multi-start optimization. Obtains
candidates and their associated acquisition function values.</p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.kg.OneShotAcquisition.surrogate">
<code class="sig-name descname">surrogate</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.kg.OneShotAcquisition.surrogate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_modular.list_surrogate">
<span id="ax-models-torch-botorch-modular-list-surrogate-module"></span><h3>ax.models.torch.botorch_modular.list_surrogate module<a class="headerlink" href="#module-ax.models.torch.botorch_modular.list_surrogate" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_modular.list_surrogate.</code><code class="sig-name descname">ListSurrogate</code><span class="sig-paren">(</span><em class="sig-param">botorch_submodel_class_per_outcome: Optional[Dict[str</em>, <em class="sig-param">Type[botorch.models.model.Model]]] = None</em>, <em class="sig-param">botorch_submodel_class: Optional[Type[botorch.models.model.Model]] = None</em>, <em class="sig-param">submodel_options_per_outcome: Optional[Dict[str</em>, <em class="sig-param">Dict[str</em>, <em class="sig-param">Any]]] = None</em>, <em class="sig-param">submodel_options: Optional[Dict[str</em>, <em class="sig-param">Any]] = None</em>, <em class="sig-param">mll_class: Type[gpytorch.mlls.marginal_log_likelihood.MarginalLogLikelihood] = &lt;class 'gpytorch.mlls.sum_marginal_log_likelihood.SumMarginalLogLikelihood'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_modular/list_surrogate.html#ListSurrogate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch_modular.surrogate.Surrogate" title="ax.models.torch.botorch_modular.surrogate.Surrogate"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch_modular.surrogate.Surrogate</span></code></a></p>
<p>Special type of <cite>Surrogate</cite> that wraps a set of submodels into
<cite>ModelListGP</cite> under the hood for multi-outcome or multi-task
models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>botorch_submodel_class_per_outcome</strong> – Mapping from metric name to
BoTorch model class that should be used as surrogate model for
that metric. Use instead of <cite>botorch_submodel_class</cite>.</p></li>
<li><p><strong>botorch_submodel_class</strong> – BoTorch <cite>Model</cite> class, shortcut for when
all submodels of this surrogate’s underlying <cite>ModelListGP</cite> are
of the same type. Use instead of <cite>botorch_submodel_class_per_
outcome</cite>.</p></li>
<li><p><strong>submodel_options_per_outcome</strong> – Optional mapping from metric name to
dictionary of kwargs for the submodel for that outcome.</p></li>
<li><p><strong>submodel_options</strong> – Optional dictionary of kwargs, shared between all
submodels.
NOTE: kwargs for submodel are <cite>submodel_options</cite> (shared) +
<cite>submodel_outions_per_outcome[submodel_outcome]</cite> (individual).</p></li>
<li><p><strong>mll_class</strong> – <cite>MarginalLogLikelihood</cite> class to use for model-fitting.</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.botorch_submodel_class">
<code class="sig-name descname">botorch_submodel_class</code><em class="property">: Optional[Type[Model]]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.botorch_submodel_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.botorch_submodel_class_per_outcome">
<code class="sig-name descname">botorch_submodel_class_per_outcome</code><em class="property">: Dict[str, Type[Model]]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.botorch_submodel_class_per_outcome" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.construct">
<code class="sig-name descname">construct</code><span class="sig-paren">(</span><em class="sig-param">training_data: List[botorch.utils.containers.TrainingData], **kwargs: Any</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/list_surrogate.html#ListSurrogate.construct"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.construct" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs the underlying BoTorch <cite>Model</cite> using the training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> – List of <cite>TrainingData</cite> for the submodels of <cite>ModelListGP</cite>.
Each training data is for one outcome, and the order of outcomes
should match the order of metrics in <cite>metric_names</cite> argument.</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments, accepts:
- <cite>metric_names</cite> (required): Names of metrics, in the same order
as training data (so if training data is <cite>[tr_A, tr_B]</cite>, the metrics
would be <cite>[“A” and “B”]</cite>). These are used to match training data
with correct submodels of <cite>ModelListGP</cite>,
- <cite>fidelity_features</cite>: Indices of columns in X that represent
fidelity,
- <cite>task_features</cite>: Indices of columns in X that represent tasks.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.device">
<em class="property">property </em><code class="sig-name descname">device</code><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.dtype">
<em class="property">property </em><code class="sig-name descname">dtype</code><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">training_data: List[botorch.utils.containers.TrainingData], bounds: List[Tuple[float, float]], task_features: List[int], feature_names: List[str], metric_names: List[str], fidelity_features: List[int], target_fidelities: Optional[Dict[int, float]] = None, candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None, state_dict: Optional[Dict[str, torch.Tensor]] = None, refit: bool = True</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/list_surrogate.html#ListSurrogate.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.fit" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.kernel_class">
<code class="sig-name descname">kernel_class</code><em class="property">: Optional[Type[Kernel]]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.kernel_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.mll_class">
<code class="sig-name descname">mll_class</code><em class="property">: Type[MarginalLogLikelihood]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.mll_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.submodel_options">
<code class="sig-name descname">submodel_options</code><em class="property">: Dict[str, Any]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.submodel_options" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.submodel_options_per_outcome">
<code class="sig-name descname">submodel_options_per_outcome</code><em class="property">: Dict[str, Dict[str, Any]]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.submodel_options_per_outcome" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.training_data">
<em class="property">property </em><code class="sig-name descname">training_data</code><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.training_data" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.training_data_per_outcome">
<em class="property">property </em><code class="sig-name descname">training_data_per_outcome</code><a class="headerlink" href="#ax.models.torch.botorch_modular.list_surrogate.ListSurrogate.training_data_per_outcome" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_modular.mes">
<span id="ax-models-torch-botorch-modular-mes-module"></span><h3>ax.models.torch.botorch_modular.mes module<a class="headerlink" href="#module-ax.models.torch.botorch_modular.mes" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.botorch_modular.mes.MaxValueEntropySearch">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_modular.mes.</code><code class="sig-name descname">MaxValueEntropySearch</code><span class="sig-paren">(</span><em class="sig-param">surrogate: ax.models.torch.botorch_modular.surrogate.Surrogate, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, botorch_acqf_class: Optional[Type[botorch.acquisition.acquisition.AcquisitionFunction]] = None, options: Optional[Dict[str, Any]] = None, pending_observations: Optional[List[torch.Tensor]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_modular/mes.html#MaxValueEntropySearch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.mes.MaxValueEntropySearch" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch_modular.acquisition.Acquisition" title="ax.models.torch.botorch_modular.acquisition.Acquisition"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch_modular.acquisition.Acquisition</span></code></a></p>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.mes.MaxValueEntropySearch.acqf">
<code class="sig-name descname">acqf</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.mes.MaxValueEntropySearch.acqf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.mes.MaxValueEntropySearch.compute_model_dependencies">
<code class="sig-name descname">compute_model_dependencies</code><span class="sig-paren">(</span><em class="sig-param">surrogate: ax.models.torch.botorch_modular.surrogate.Surrogate, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, pending_observations: Optional[List[torch.Tensor]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, target_fidelities: Optional[Dict[int, float]] = None, options: Optional[Dict[str, Any]] = None</em><span class="sig-paren">)</span> → Dict[str, Any]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/mes.html#MaxValueEntropySearch.compute_model_dependencies"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.mes.MaxValueEntropySearch.compute_model_dependencies" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes inputs to acquisition function class based on the given
surrogate model.</p>
<p>NOTE: When subclassing <cite>Acquisition</cite> from a superclass where this
method returns a non-empty dictionary of kwargs to <cite>AcquisitionFunction</cite>,
call <cite>super().compute_model_dependencies</cite> and then update that
dictionary of options with the options for the subclass you are creating
(unless the superclass’ model dependencies should not be propagated to
the subclass). See <cite>MultiFidelityKnowledgeGradient.compute_model_dependencies</cite>
for an example.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>surrogate</strong> – The surrogate object containing the BoTorch <cite>Model</cite>,
with which this <cite>Acquisition</cite> is to be used.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X in
the training data of the surrogate model.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>pending_observations</strong> – A list of tensors, each of which contains
points whose evaluation is pending (i.e. that have been
submitted for evaluation) for a given outcome. A list
of m (k_i x d) feature tensors X for m outcomes and k_i,
pending observations for outcome i.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>target_fidelities</strong> – Optional mapping from parameter name to its
target fidelity, applicable to fidelity parameters only.</p></li>
<li><p><strong>options</strong> – The <cite>options</cite> kwarg dict, passed on initialization of
the <cite>Acquisition</cite> object.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Returns: A dictionary of surrogate model-dependent options, to be passed</dt><dd><p>as kwargs to BoTorch`AcquisitionFunction` constructor.</p>
</dd>
</dl>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.mes.MaxValueEntropySearch.default_botorch_acqf_class">
<code class="sig-name descname">default_botorch_acqf_class</code><a class="headerlink" href="#ax.models.torch.botorch_modular.mes.MaxValueEntropySearch.default_botorch_acqf_class" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.acquisition.max_value_entropy_search.qMaxValueEntropy</span></code></p>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.mes.MaxValueEntropySearch.optimize">
<code class="sig-name descname">optimize</code><span class="sig-paren">(</span><em class="sig-param">bounds: torch.Tensor, n: int, optimizer_class: Optional[ax.models.torch.botorch_modular.acquisition.Optimizer] = None, inequality_constraints: Optional[List[Tuple[torch.Tensor, torch.Tensor, float]]] = None, fixed_features: Optional[Dict[int, float]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, optimizer_options: Optional[Dict[str, Any]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/mes.html#MaxValueEntropySearch.optimize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.mes.MaxValueEntropySearch.optimize" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a set of candidates via multi-start optimization. Obtains
candidates and their associated acquisition function values.</p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.mes.MaxValueEntropySearch.surrogate">
<code class="sig-name descname">surrogate</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.mes.MaxValueEntropySearch.surrogate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="class">
<dt id="ax.models.torch.botorch_modular.mes.MultiFidelityMaxValueEntropySearch">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_modular.mes.</code><code class="sig-name descname">MultiFidelityMaxValueEntropySearch</code><span class="sig-paren">(</span><em class="sig-param">surrogate: ax.models.torch.botorch_modular.surrogate.Surrogate, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, botorch_acqf_class: Optional[Type[botorch.acquisition.acquisition.AcquisitionFunction]] = None, options: Optional[Dict[str, Any]] = None, pending_observations: Optional[List[torch.Tensor]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_modular/mes.html#MultiFidelityMaxValueEntropySearch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.mes.MultiFidelityMaxValueEntropySearch" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition" title="ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition</span></code></a>, <a class="reference internal" href="#ax.models.torch.botorch_modular.mes.MaxValueEntropySearch" title="ax.models.torch.botorch_modular.mes.MaxValueEntropySearch"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch_modular.mes.MaxValueEntropySearch</span></code></a></p>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.mes.MultiFidelityMaxValueEntropySearch.acqf">
<code class="sig-name descname">acqf</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.mes.MultiFidelityMaxValueEntropySearch.acqf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.mes.MultiFidelityMaxValueEntropySearch.compute_model_dependencies">
<code class="sig-name descname">compute_model_dependencies</code><span class="sig-paren">(</span><em class="sig-param">surrogate: ax.models.torch.botorch_modular.surrogate.Surrogate, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, target_fidelities: Optional[Dict[int, float]] = None, pending_observations: Optional[List[torch.Tensor]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, options: Optional[Dict[str, Any]] = None</em><span class="sig-paren">)</span> → Dict[str, Any]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/mes.html#MultiFidelityMaxValueEntropySearch.compute_model_dependencies"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.mes.MultiFidelityMaxValueEntropySearch.compute_model_dependencies" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes inputs to acquisition function class based on the given
surrogate model.</p>
<p>NOTE: When subclassing <cite>Acquisition</cite> from a superclass where this
method returns a non-empty dictionary of kwargs to <cite>AcquisitionFunction</cite>,
call <cite>super().compute_model_dependencies</cite> and then update that
dictionary of options with the options for the subclass you are creating
(unless the superclass’ model dependencies should not be propagated to
the subclass). See <cite>MultiFidelityKnowledgeGradient.compute_model_dependencies</cite>
for an example.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>surrogate</strong> – The surrogate object containing the BoTorch <cite>Model</cite>,
with which this <cite>Acquisition</cite> is to be used.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X in
the training data of the surrogate model.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>pending_observations</strong> – A list of tensors, each of which contains
points whose evaluation is pending (i.e. that have been
submitted for evaluation) for a given outcome. A list
of m (k_i x d) feature tensors X for m outcomes and k_i,
pending observations for outcome i.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>target_fidelities</strong> – Optional mapping from parameter name to its
target fidelity, applicable to fidelity parameters only.</p></li>
<li><p><strong>options</strong> – The <cite>options</cite> kwarg dict, passed on initialization of
the <cite>Acquisition</cite> object.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Returns: A dictionary of surrogate model-dependent options, to be passed</dt><dd><p>as kwargs to BoTorch`AcquisitionFunction` constructor.</p>
</dd>
</dl>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.mes.MultiFidelityMaxValueEntropySearch.default_botorch_acqf_class">
<code class="sig-name descname">default_botorch_acqf_class</code><a class="headerlink" href="#ax.models.torch.botorch_modular.mes.MultiFidelityMaxValueEntropySearch.default_botorch_acqf_class" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">botorch.acquisition.max_value_entropy_search.qMultiFidelityMaxValueEntropy</span></code></p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.mes.MultiFidelityMaxValueEntropySearch.surrogate">
<code class="sig-name descname">surrogate</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.mes.MultiFidelityMaxValueEntropySearch.surrogate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_modular.model">
<span id="ax-models-torch-botorch-modular-model-module"></span><h3>ax.models.torch.botorch_modular.model module<a class="headerlink" href="#module-ax.models.torch.botorch_modular.model" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.botorch_modular.model.BoTorchModel">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_modular.model.</code><code class="sig-name descname">BoTorchModel</code><span class="sig-paren">(</span><em class="sig-param">acquisition_class: Optional[Type[ax.models.torch.botorch_modular.acquisition.Acquisition]] = None</em>, <em class="sig-param">acquisition_options: Optional[Dict[str</em>, <em class="sig-param">Any]] = None</em>, <em class="sig-param">botorch_acqf_class: Optional[Type[botorch.acquisition.acquisition.AcquisitionFunction]] = None</em>, <em class="sig-param">surrogate: Optional[ax.models.torch.botorch_modular.surrogate.Surrogate] = None</em>, <em class="sig-param">surrogate_options: Optional[Dict[str</em>, <em class="sig-param">Any]] = None</em>, <em class="sig-param">surrogate_fit_options: Optional[Dict[str</em>, <em class="sig-param">Any]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_modular/model.html#BoTorchModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.model.BoTorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch_base.TorchModel" title="ax.models.torch_base.TorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch_base.TorchModel</span></code></a>, <a class="reference internal" href="utils.html#ax.utils.common.base.Base" title="ax.utils.common.base.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.utils.common.base.Base</span></code></a></p>
<p><strong>All classes in ‘botorch_modular’ directory are under
construction, incomplete, and should be treated as alpha
versions only.</strong></p>
<p>Modular <cite>Model</cite> class for combining BoTorch subcomponents
in Ax. Specified via <cite>Surrogate</cite> and <cite>Acquisition</cite>, which wrap
BoTorch <cite>Model</cite> and <cite>AcquisitionFunction</cite>, respectively, for
convenient use in Ax.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acquisition_class</strong> – Type of <cite>Acquisition</cite> to be used in
this model, auto-selected based on experiment and data
if not specified.</p></li>
<li><p><strong>acquisition_options</strong> – Optional dict of kwargs, passed to
the constructor of BoTorch <cite>AcquisitionFunction</cite>.</p></li>
<li><p><strong>botorch_acqf_class</strong> – Type of <cite>AcquisitionFunction</cite> to be
used in this model, auto-selected based on experiment
and data if not specified.</p></li>
<li><p><strong>surrogate</strong> – An instance of <cite>Surrogate</cite> to be used as part of
this model; if not specified, type of <cite>Surrogate</cite> and
underlying BoTorch <cite>Model</cite> will be auto-selected based
on experiment and data, with kwargs in <cite>surrogate_options</cite>
applied.</p></li>
<li><p><strong>surrogate_options</strong> – Optional dict of kwargs for <cite>Surrogate</cite>
(used if no pre-instantiated Surrogate via is passed via <cite>surrogate</cite>).</p></li>
<li><p><strong>surrogate_fit_options</strong> – Optional dict of kwargs, passed to
<cite>Surrogate.fit</cite>, including:
- state_dict: <cite>state_dict</cite> for the underlying BoTorch <cite>Model</cite>,
- refit_on_update: Whether to re-fit the underlying BoTorch <cite>Model</cite>
when updating it with new data.</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.model.BoTorchModel.acquisition_class">
<code class="sig-name descname">acquisition_class</code><em class="property">: Type[Acquisition]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.model.BoTorchModel.acquisition_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.model.BoTorchModel.acquisition_options">
<code class="sig-name descname">acquisition_options</code><em class="property">: Dict[str, Any]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.model.BoTorchModel.acquisition_options" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.model.BoTorchModel.best_point">
<code class="sig-name descname">best_point</code><span class="sig-paren">(</span><em class="sig-param">bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Optional[torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/model.html#BoTorchModel.best_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.model.BoTorchModel.best_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Identify the current best point, satisfying the constraints in the same
format as to gen.</p>
<p>Return None if no such point can be identified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value in the best point.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>d-tensor of the best point.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.model.BoTorchModel.botorch_acqf_class">
<em class="property">property </em><code class="sig-name descname">botorch_acqf_class</code><a class="headerlink" href="#ax.models.torch.botorch_modular.model.BoTorchModel.botorch_acqf_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.model.BoTorchModel.evaluate_acquisition_function">
<code class="sig-name descname">evaluate_acquisition_function</code><span class="sig-paren">(</span><em class="sig-param">X: torch.Tensor, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, pending_observations: Optional[List[torch.Tensor]] = None, target_fidelities: Optional[Dict[int, float]] = None, acq_options: Optional[Dict[str, Any]] = None</em><span class="sig-paren">)</span> → torch.Tensor<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/model.html#BoTorchModel.evaluate_acquisition_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.model.BoTorchModel.evaluate_acquisition_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the acquisition function on the candidate set <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – (j x d) tensor of the j points at which to evaluate the acquisition
function.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A single-element tensor with the acquisition value for these points.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.model.BoTorchModel.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], bounds: List[Tuple[float, float]], task_features: List[int], feature_names: List[str], metric_names: List[str], fidelity_features: List[int], target_fidelities: Optional[Dict[int, float]] = None, candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/model.html#BoTorchModel.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.model.BoTorchModel.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to m outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – A list of m (k_i x d) feature tensors X. Number of rows k_i can
vary from i=1,…,m.</p></li>
<li><p><strong>Ys</strong> – The corresponding list of m (k_i x 1) outcome tensors Y, for
each outcome.</p></li>
<li><p><strong>Yvars</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>bounds</strong> – A list of d (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>task_features</strong> – Columns of X that take integer values and should be
treated as task parameters.</p></li>
<li><p><strong>feature_names</strong> – Names of each column of X.</p></li>
<li><p><strong>metric_names</strong> – Names of each outcome Y in Ys.</p></li>
<li><p><strong>fidelity_features</strong> – Columns of X that should be treated as fidelity
parameters.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.model.BoTorchModel.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, pending_observations: Optional[List[torch.Tensor]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor, Dict[str, Any], Optional[List[Optional[Dict[str, Any]]]]]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/model.html#BoTorchModel.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.model.BoTorchModel.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>pending_observations</strong> – A list of m (k_i x d) feature tensors X
for m outcomes and k_i pending observations for outcome i.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (i.e., according to <cite>round-trip</cite> transformations).</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>4-element tuple containing</p>
<ul class="simple">
<li><p>(n x d) tensor of generated points.</p></li>
<li><p>n-tensor of weights for each point.</p></li>
<li><p>Generation metadata</p></li>
<li><dl class="simple">
<dt>Dictionary of model-specific metadata for the given</dt><dd><p>generation candidates</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.model.BoTorchModel.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/model.html#BoTorchModel.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.model.BoTorchModel.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – (j x d) tensor of the j points at which to make predictions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) tensor of outcome predictions at X.</p></li>
<li><p>(j x m x m) tensor of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.model.BoTorchModel.surrogate">
<em class="property">property </em><code class="sig-name descname">surrogate</code><a class="headerlink" href="#ax.models.torch.botorch_modular.model.BoTorchModel.surrogate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.model.BoTorchModel.surrogate_fit_options">
<code class="sig-name descname">surrogate_fit_options</code><em class="property">: Dict[str, Any]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.model.BoTorchModel.surrogate_fit_options" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.model.BoTorchModel.surrogate_options">
<code class="sig-name descname">surrogate_options</code><em class="property">: Dict[str, Any]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.model.BoTorchModel.surrogate_options" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_modular.multi_fidelity">
<span id="ax-models-torch-botorch-modular-multi-fidelity-module"></span><h3>ax.models.torch.botorch_modular.multi_fidelity module<a class="headerlink" href="#module-ax.models.torch.botorch_modular.multi_fidelity" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_modular.multi_fidelity.</code><code class="sig-name descname">MultiFidelityAcquisition</code><span class="sig-paren">(</span><em class="sig-param">surrogate: ax.models.torch.botorch_modular.surrogate.Surrogate, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, botorch_acqf_class: Optional[Type[botorch.acquisition.acquisition.AcquisitionFunction]] = None, options: Optional[Dict[str, Any]] = None, pending_observations: Optional[List[torch.Tensor]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_modular/multi_fidelity.html#MultiFidelityAcquisition"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch_modular.acquisition.Acquisition" title="ax.models.torch.botorch_modular.acquisition.Acquisition"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch_modular.acquisition.Acquisition</span></code></a></p>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition.acqf">
<code class="sig-name descname">acqf</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition.acqf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition.compute_model_dependencies">
<code class="sig-name descname">compute_model_dependencies</code><span class="sig-paren">(</span><em class="sig-param">surrogate: ax.models.torch.botorch_modular.surrogate.Surrogate, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, target_fidelities: Optional[Dict[int, float]] = None, pending_observations: Optional[List[torch.Tensor]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, options: Optional[Dict[str, Any]] = None</em><span class="sig-paren">)</span> → Dict[str, Any]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/multi_fidelity.html#MultiFidelityAcquisition.compute_model_dependencies"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition.compute_model_dependencies" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes inputs to acquisition function class based on the given
surrogate model.</p>
<p>NOTE: When subclassing <cite>Acquisition</cite> from a superclass where this
method returns a non-empty dictionary of kwargs to <cite>AcquisitionFunction</cite>,
call <cite>super().compute_model_dependencies</cite> and then update that
dictionary of options with the options for the subclass you are creating
(unless the superclass’ model dependencies should not be propagated to
the subclass). See <cite>MultiFidelityKnowledgeGradient.compute_model_dependencies</cite>
for an example.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>surrogate</strong> – The surrogate object containing the BoTorch <cite>Model</cite>,
with which this <cite>Acquisition</cite> is to be used.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X in
the training data of the surrogate model.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>pending_observations</strong> – A list of tensors, each of which contains
points whose evaluation is pending (i.e. that have been
submitted for evaluation) for a given outcome. A list
of m (k_i x d) feature tensors X for m outcomes and k_i,
pending observations for outcome i.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>target_fidelities</strong> – Optional mapping from parameter name to its
target fidelity, applicable to fidelity parameters only.</p></li>
<li><p><strong>options</strong> – The <cite>options</cite> kwarg dict, passed on initialization of
the <cite>Acquisition</cite> object.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Returns: A dictionary of surrogate model-dependent options, to be passed</dt><dd><p>as kwargs to BoTorch`AcquisitionFunction` constructor.</p>
</dd>
</dl>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition.surrogate">
<code class="sig-name descname">surrogate</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.multi_fidelity.MultiFidelityAcquisition.surrogate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_modular.surrogate">
<span id="ax-models-torch-botorch-modular-surrogate-module"></span><h3>ax.models.torch.botorch_modular.surrogate module<a class="headerlink" href="#module-ax.models.torch.botorch_modular.surrogate" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.botorch_modular.surrogate.</code><code class="sig-name descname">Surrogate</code><span class="sig-paren">(</span><em class="sig-param">botorch_model_class: Type[botorch.models.model.Model], mll_class: Type[gpytorch.mlls.marginal_log_likelihood.MarginalLogLikelihood] = &lt;class 'gpytorch.mlls.exact_marginal_log_likelihood.ExactMarginalLogLikelihood'&gt;, model_options: Optional[Dict[str, Any]] = None, kernel_class: Optional[Type[gpytorch.kernels.kernel.Kernel]] = None, kernel_options: Optional[Dict[str, Any]] = None, likelihood: Optional[Type[gpytorch.likelihoods.likelihood.Likelihood]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/botorch_modular/surrogate.html#Surrogate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="utils.html#ax.utils.common.base.Base" title="ax.utils.common.base.Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.utils.common.base.Base</span></code></a></p>
<p><strong>All classes in ‘botorch_modular’ directory are under
construction, incomplete, and should be treated as alpha
versions only.</strong></p>
<p>Ax wrapper for BoTorch <cite>Model</cite>, subcomponent of <cite>BoTorchModel</cite>
and is not meant to be used outside of it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>botorch_model_class</strong> – <cite>Model</cite> class to be used as the underlying
BoTorch model.</p></li>
<li><p><strong>mll_class</strong> – <cite>MarginalLogLikelihood</cite> class to use for model-fitting.</p></li>
<li><p><strong>model_options</strong> – Dictionary of options / kwargs for the BoTorch
<cite>Model</cite> constructed during <cite>Surrogate.fit</cite>.</p></li>
<li><p><strong>kernel_class</strong> – <cite>Kernel</cite> class, not yet used. Will be used to
construct custom BoTorch <cite>Model</cite> in the future.</p></li>
<li><p><strong>kernel_options</strong> – Kernel kwargs, not yet used. Will be used to
construct custom BoTorch <cite>Model</cite> in the future.</p></li>
<li><p><strong>likelihood</strong> – <cite>Likelihood</cite> class, not yet used. Will be used to
construct custom BoTorch <cite>Model</cite> in the future.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.best_in_sample_point">
<code class="sig-name descname">best_in_sample_point</code><span class="sig-paren">(</span><em class="sig-param">bounds: List[Tuple[float, float]], objective_weights: Optional[torch.Tensor], outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, float]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/surrogate.html#Surrogate.best_in_sample_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.best_in_sample_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds the best observed point and the corresponding observed outcome
values.</p>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.best_out_of_sample_point">
<code class="sig-name descname">best_out_of_sample_point</code><span class="sig-paren">(</span><em class="sig-param">bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, fidelity_features: Optional[List[int]] = None, target_fidelities: Optional[Dict[int, float]] = None, options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/surrogate.html#Surrogate.best_out_of_sample_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.best_out_of_sample_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds the best predicted point and the corresponding value of the
appropriate best point acquisition function.</p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.botorch_model_class">
<code class="sig-name descname">botorch_model_class</code><em class="property">: Type[Model]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.botorch_model_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.compute_diagnostics">
<code class="sig-name descname">compute_diagnostics</code><span class="sig-paren">(</span><span class="sig-paren">)</span> → Dict[str, Any]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/surrogate.html#Surrogate.compute_diagnostics"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.compute_diagnostics" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes model diagnostics like cross-validation measure of fit, etc.</p>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.construct">
<code class="sig-name descname">construct</code><span class="sig-paren">(</span><em class="sig-param">training_data: botorch.utils.containers.TrainingData</em>, <em class="sig-param">**kwargs: Any</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/surrogate.html#Surrogate.construct"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.construct" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs the underlying BoTorch <cite>Model</cite> using the training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> – Training data for the model (for one outcome for
the default <cite>Surrogate</cite>, with the exception of batched
multi-output case, where training data is formatted with just
one X and concatenated Ys).</p></li>
<li><p><strong>**kwargs</strong> – Optional keyword arguments, expects any of:
- “fidelity_features”: Indices of columns in X that represent
fidelity.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.device">
<em class="property">property </em><code class="sig-name descname">device</code><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.dtype">
<em class="property">property </em><code class="sig-name descname">dtype</code><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">training_data: botorch.utils.containers.TrainingData, bounds: List[Tuple[float, float]], task_features: List[int], feature_names: List[str], metric_names: List[str], fidelity_features: List[int], target_fidelities: Optional[Dict[int, float]] = None, candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None, state_dict: Optional[Dict[str, torch.Tensor]] = None, refit: bool = True</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/surrogate.html#Surrogate.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.fit" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.from_BoTorch">
<em class="property">classmethod </em><code class="sig-name descname">from_BoTorch</code><span class="sig-paren">(</span><em class="sig-param">model: botorch.models.model.Model</em>, <em class="sig-param">mll_class: Type[gpytorch.mlls.marginal_log_likelihood.MarginalLogLikelihood] = &lt;class 'gpytorch.mlls.exact_marginal_log_likelihood.ExactMarginalLogLikelihood'&gt;</em><span class="sig-paren">)</span> → ax.models.torch.botorch_modular.surrogate.Surrogate<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/surrogate.html#Surrogate.from_BoTorch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.from_BoTorch" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate a <cite>Surrogate</cite> from a pre-instantiated Botorch <cite>Model</cite>.</p>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.kernel_class">
<code class="sig-name descname">kernel_class</code><em class="property">: Optional[Type[Kernel]]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.kernel_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.mll_class">
<code class="sig-name descname">mll_class</code><em class="property">: Type[MarginalLogLikelihood]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.mll_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.model">
<em class="property">property </em><code class="sig-name descname">model</code><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.model" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.model_options">
<code class="sig-name descname">model_options</code><em class="property">: Dict[str, Any]</em><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.model_options" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.pareto_frontier">
<code class="sig-name descname">pareto_frontier</code><span class="sig-paren">(</span><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/surrogate.html#Surrogate.pareto_frontier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.pareto_frontier" title="Permalink to this definition">¶</a></dt>
<dd><p>For multi-objective optimization, retrieve Pareto frontier instead
of best point.</p>
<dl class="simple">
<dt>Returns: A two-tuple of:</dt><dd><ul class="simple">
<li><p>tensor of points in the feature space,</p></li>
<li><p>tensor of corresponding (multiple) outcomes.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/surrogate.html#Surrogate.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts outcomes given a model and input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – A botorch Model.</p></li>
<li><p><strong>X</strong> – A <cite>n x d</cite> tensor of input parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The predicted posterior mean as an <cite>n x o</cite>-dim tensor.
Tensor: The predicted posterior covariance as a <cite>n x o x o</cite>-dim tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.training_data">
<em class="property">property </em><code class="sig-name descname">training_data</code><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.training_data" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.training_data_per_outcome">
<em class="property">property </em><code class="sig-name descname">training_data_per_outcome</code><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.training_data_per_outcome" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.botorch_modular.surrogate.Surrogate.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">training_data: botorch.utils.containers.TrainingData, bounds: List[Tuple[float, float]], task_features: List[int], feature_names: List[str], metric_names: List[str], fidelity_features: List[int], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None, state_dict: Optional[Dict[str, torch.Tensor]] = None, refit: bool = True</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/surrogate.html#Surrogate.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.surrogate.Surrogate.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the surrogate model with new data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>training_data</strong> – Surrogate training_data containing all the data the model
should use for inference. NOTE: this should not be just the new data
since the last time the model was updated, but all available
data.</p></li>
<li><p><strong>refit</strong> – Whether to re-optimize model parameters or just add the new
data to data used for inference.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.botorch_modular.utils">
<span id="ax-models-torch-botorch-modular-utils-module"></span><h3>ax.models.torch.botorch_modular.utils module<a class="headerlink" href="#module-ax.models.torch.botorch_modular.utils" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="ax.models.torch.botorch_modular.utils.choose_botorch_acqf_class">
<code class="sig-prename descclassname">ax.models.torch.botorch_modular.utils.</code><code class="sig-name descname">choose_botorch_acqf_class</code><span class="sig-paren">(</span><span class="sig-paren">)</span> → Type[botorch.acquisition.acquisition.AcquisitionFunction]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/utils.html#choose_botorch_acqf_class"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.utils.choose_botorch_acqf_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Chooses a BoTorch <cite>AcquisitionFunction</cite> class.</p>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_modular.utils.choose_model_class">
<code class="sig-prename descclassname">ax.models.torch.botorch_modular.utils.</code><code class="sig-name descname">choose_model_class</code><span class="sig-paren">(</span><em class="sig-param">Yvars: List[torch.Tensor], task_features: List[int], fidelity_features: List[int]</em><span class="sig-paren">)</span> → Type[botorch.models.model.Model]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/utils.html#choose_model_class"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.utils.choose_model_class" title="Permalink to this definition">¶</a></dt>
<dd><p>Chooses a BoTorch <cite>Model</cite> using the given data (currently just Yvars)
and its properties (information about task and fidelity features).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Yvars</strong> – List of tensors, each representing observation noise for a
given outcome, where outcomes are in the same order as in Xs.</p></li>
<li><p><strong>task_features</strong> – List of columns of X that are tasks.</p></li>
<li><p><strong>fidelity_features</strong> – List of columns of X that are fidelity parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A BoTorch <cite>Model</cite> class.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_modular.utils.construct_acquisition_and_optimizer_options">
<code class="sig-prename descclassname">ax.models.torch.botorch_modular.utils.</code><code class="sig-name descname">construct_acquisition_and_optimizer_options</code><span class="sig-paren">(</span><em class="sig-param">acqf_options: Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]], model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None</em><span class="sig-paren">)</span> → Tuple[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]], Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/utils.html#construct_acquisition_and_optimizer_options"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.utils.construct_acquisition_and_optimizer_options" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract acquisition and optimizer options from <cite>model_gen_options</cite>.</p>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_modular.utils.construct_single_training_data">
<code class="sig-prename descclassname">ax.models.torch.botorch_modular.utils.</code><code class="sig-name descname">construct_single_training_data</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor]</em><span class="sig-paren">)</span> → botorch.utils.containers.TrainingData<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/utils.html#construct_single_training_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.utils.construct_single_training_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a <cite>TrainingData</cite> object for a single-outcome model or a batched
multi-output model. <strong>This function assumes that a single `TrainingData` is
expected (so if all Xs are equal, it will produce `TrainingData` for a batched
multi-output model).</strong></p>
<p>NOTE: All four outputs are organized as lists over outcomes. E.g. if there are two
outcomes, ‘x’ and ‘y’, the Xs are formatted like so: <cite>[Xs_x_ndarray, Xs_y_ndarray]</cite>.
We specifically do not assume that every point is observed for every outcome.
This means that the array for each of those outcomes may be different, and in
particular could have a different length (e.g. if a particular arm was observed
only for half of the outcomes, it would be present in half of the arrays in the
list but not the other half.)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>TrainingData</cite> object with training data for single outcome or with
batched multi-output training data if appropriate for given model and if
all X inputs in Xs are equal.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_modular.utils.construct_training_data_list">
<code class="sig-prename descclassname">ax.models.torch.botorch_modular.utils.</code><code class="sig-name descname">construct_training_data_list</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor]</em><span class="sig-paren">)</span> → List[botorch.utils.containers.TrainingData]<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/utils.html#construct_training_data_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.utils.construct_training_data_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a list of <cite>TrainingData</cite> objects, for use in <cite>ListSurrogate</cite> and
<cite>ModelListGP</cite>. Each <cite>TrainingData</cite> corresponds to an outcome.</p>
<p>NOTE: All four outputs are organized as lists over outcomes. E.g. if there are two
outcomes, ‘x’ and ‘y’, the Xs are formatted like so: <cite>[Xs_x_ndarray, Xs_y_ndarray]</cite>.
We specifically do not assume that every point is observed for every outcome.
This means that the array for each of those outcomes may be different, and in
particular could have a different length (e.g. if a particular arm was observed
only for half of the outcomes, it would be present in half of the arrays in the
list but not the other half.)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A list of <cite>TrainingData</cite> for all outcomes, preserves the order of Xs.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_modular.utils.use_model_list">
<code class="sig-prename descclassname">ax.models.torch.botorch_modular.utils.</code><code class="sig-name descname">use_model_list</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], botorch_model_class: Type[botorch.models.model.Model]</em><span class="sig-paren">)</span> → bool<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/utils.html#use_model_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.utils.use_model_list" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="function">
<dt id="ax.models.torch.botorch_modular.utils.validate_data_format">
<code class="sig-prename descclassname">ax.models.torch.botorch_modular.utils.</code><code class="sig-name descname">validate_data_format</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], metric_names: List[str]</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/botorch_modular/utils.html#validate_data_format"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.botorch_modular.utils.validate_data_format" title="Permalink to this definition">¶</a></dt>
<dd><p>Validates that Xs, Ys, Yvars, and metric names all have equal lengths.</p>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.cbo_lcea">
<span id="ax-models-torch-cbo-lcea-module"></span><h3>ax.models.torch.cbo_lcea module<a class="headerlink" href="#module-ax.models.torch.cbo_lcea" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.cbo_lcea.LCEABO">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.cbo_lcea.</code><code class="sig-name descname">LCEABO</code><span class="sig-paren">(</span><em class="sig-param">decomposition: Dict[str, List[str]], cat_feature_dict: Optional[Dict] = None, embs_feature_dict: Optional[Dict] = None, context_weight_dict: Optional[Dict] = None, embs_dim_list: Optional[List[int]] = None, gp_model_args: Optional[Dict[str, Any]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/cbo_lcea.html#LCEABO"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.cbo_lcea.LCEABO" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch.BotorchModel" title="ax.models.torch.botorch.BotorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch.BotorchModel</span></code></a></p>
<p>Does Bayesian optimization with Latent Context Embedding Additive (LCE-A) GP.
The parameter space decomposition must be provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decomposition</strong> – Keys are context names. Values are the lists of parameter
names belong to the context, e.g.
{‘context1’: [‘p1_c1’, ‘p2_c1’],’context2’: [‘p1_c2’, ‘p2_c2’]}.</p></li>
<li><p><strong>gp_model_args</strong> – Dictionary of kwargs to pass to GP model training.
- train_embedding: Boolen. If true, we will train context embedding;
otherwise, we use pre-trained embeddings from embds_feature_dict only.
Default is True.</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_lcea.LCEABO.Xs">
<code class="sig-name descname">Xs</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_lcea.LCEABO.Xs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_lcea.LCEABO.Ys">
<code class="sig-name descname">Ys</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_lcea.LCEABO.Ys" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_lcea.LCEABO.Yvars">
<code class="sig-name descname">Yvars</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_lcea.LCEABO.Yvars" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.cbo_lcea.LCEABO.best_point">
<code class="sig-name descname">best_point</code><span class="sig-paren">(</span><em class="sig-param">bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Optional[torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/cbo_lcea.html#LCEABO.best_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.cbo_lcea.LCEABO.best_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Identify the current best point, satisfying the constraints in the same
format as to gen.</p>
<p>Return None if no such point can be identified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value in the best point.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>d-tensor of the best point.</p>
</dd>
</dl>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_lcea.LCEABO.device">
<code class="sig-name descname">device</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_lcea.LCEABO.device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_lcea.LCEABO.dtype">
<code class="sig-name descname">dtype</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_lcea.LCEABO.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.cbo_lcea.LCEABO.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], bounds: List[Tuple[float, float]], task_features: List[int], feature_names: List[str], metric_names: List[str], fidelity_features: List[int], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/cbo_lcea.html#LCEABO.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.cbo_lcea.LCEABO.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to m outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – A list of m (k_i x d) feature tensors X. Number of rows k_i can
vary from i=1,…,m.</p></li>
<li><p><strong>Ys</strong> – The corresponding list of m (k_i x 1) outcome tensors Y, for
each outcome.</p></li>
<li><p><strong>Yvars</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>bounds</strong> – A list of d (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>task_features</strong> – Columns of X that take integer values and should be
treated as task parameters.</p></li>
<li><p><strong>feature_names</strong> – Names of each column of X.</p></li>
<li><p><strong>metric_names</strong> – Names of each outcome Y in Ys.</p></li>
<li><p><strong>fidelity_features</strong> – Columns of X that should be treated as fidelity
parameters.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.cbo_lcea.LCEABO.get_and_fit_model">
<code class="sig-name descname">get_and_fit_model</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], task_features: List[int], fidelity_features: List[int], metric_names: List[str], state_dict: Optional[Dict[str, torch.Tensor]] = None, fidelity_model_id: Optional[int] = None, **kwargs: Any</em><span class="sig-paren">)</span> → botorch.models.gpytorch.GPyTorchModel<a class="reference internal" href="_modules/ax/models/torch/cbo_lcea.html#LCEABO.get_and_fit_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.cbo_lcea.LCEABO.get_and_fit_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a fitted LCEAGP model for each outcome.
:param Xs: X for each outcome.
:param Ys: Y for each outcome.
:param Yvars: Noise variance of Y for each outcome.</p>
<p>Returns: Fitted LCEAGP model.</p>
</dd></dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.cbo_lcea.get_map_model">
<code class="sig-prename descclassname">ax.models.torch.cbo_lcea.</code><code class="sig-name descname">get_map_model</code><span class="sig-paren">(</span><em class="sig-param">train_X: torch.Tensor, train_Y: torch.Tensor, train_Yvar: torch.Tensor, decomposition: Dict[str, List[int]], train_embedding: bool = True, cat_feature_dict: Optional[Dict] = None, embs_feature_dict: Optional[Dict] = None, embs_dim_list: Optional[List[int]] = None, context_weight_dict: Optional[Dict] = None</em><span class="sig-paren">)</span> → Tuple[botorch.models.contextual.LCEAGP, gpytorch.mlls.exact_marginal_log_likelihood.ExactMarginalLogLikelihood]<a class="reference internal" href="_modules/ax/models/torch/cbo_lcea.html#get_map_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.cbo_lcea.get_map_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain MAP fitting of Latent Context Embedding Additive (LCE-A) GP.</p>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.cbo_lcem">
<span id="ax-models-torch-cbo-lcem-module"></span><h3>ax.models.torch.cbo_lcem module<a class="headerlink" href="#module-ax.models.torch.cbo_lcem" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.cbo_lcem.LCEMBO">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.cbo_lcem.</code><code class="sig-name descname">LCEMBO</code><span class="sig-paren">(</span><em class="sig-param">context_cat_feature: Optional[torch.Tensor] = None</em>, <em class="sig-param">context_emb_feature: Optional[torch.Tensor] = None</em>, <em class="sig-param">embs_dim_list: Optional[List[int]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/cbo_lcem.html#LCEMBO"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.cbo_lcem.LCEMBO" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch.BotorchModel" title="ax.models.torch.botorch.BotorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch.BotorchModel</span></code></a></p>
<p>Does Bayesian optimization with LCE-M GP.</p>
<dl class="attribute">
<dt id="ax.models.torch.cbo_lcem.LCEMBO.Xs">
<code class="sig-name descname">Xs</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_lcem.LCEMBO.Xs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_lcem.LCEMBO.Ys">
<code class="sig-name descname">Ys</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_lcem.LCEMBO.Ys" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_lcem.LCEMBO.Yvars">
<code class="sig-name descname">Yvars</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_lcem.LCEMBO.Yvars" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_lcem.LCEMBO.device">
<code class="sig-name descname">device</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_lcem.LCEMBO.device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_lcem.LCEMBO.dtype">
<code class="sig-name descname">dtype</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_lcem.LCEMBO.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.cbo_lcem.LCEMBO.get_and_fit_model">
<code class="sig-name descname">get_and_fit_model</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], task_features: List[int], fidelity_features: List[int], metric_names: List[str], state_dict: Optional[Dict[str, torch.Tensor]] = None, fidelity_model_id: Optional[int] = None, **kwargs: Any</em><span class="sig-paren">)</span> → botorch.models.model_list_gp_regression.ModelListGP<a class="reference internal" href="_modules/ax/models/torch/cbo_lcem.html#LCEMBO.get_and_fit_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.cbo_lcem.LCEMBO.get_and_fit_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a fitted multi-task contextual GP model for each outcome.
:param Xs: List of X data, one tensor per outcome.
:param Ys: List of Y data, one tensor per outcome.
:param Yvars: List of Noise variance of Yvar data, one tensor per outcome.</p>
<p>Returns: Fitted multi-task contextual GP model.</p>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.cbo_sac">
<span id="ax-models-torch-cbo-sac-module"></span><h3>ax.models.torch.cbo_sac module<a class="headerlink" href="#module-ax.models.torch.cbo_sac" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.cbo_sac.SACBO">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.cbo_sac.</code><code class="sig-name descname">SACBO</code><span class="sig-paren">(</span><em class="sig-param">decomposition: Dict[str, List[str]]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/cbo_sac.html#SACBO"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.cbo_sac.SACBO" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch.BotorchModel" title="ax.models.torch.botorch.BotorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch.BotorchModel</span></code></a></p>
<p>Does Bayesian optimization with structural additive contextual GP (SACGP).
The parameter space decomposition must be provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>decomposition</strong> – Keys are context names. Values are the lists of parameter
names belong to the context, e.g.
{‘context1’: [‘p1_c1’, ‘p2_c1’],’context2’: [‘p1_c2’, ‘p2_c2’]}.</p>
</dd>
</dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_sac.SACBO.Xs">
<code class="sig-name descname">Xs</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_sac.SACBO.Xs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_sac.SACBO.Ys">
<code class="sig-name descname">Ys</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_sac.SACBO.Ys" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_sac.SACBO.Yvars">
<code class="sig-name descname">Yvars</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_sac.SACBO.Yvars" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_sac.SACBO.device">
<code class="sig-name descname">device</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_sac.SACBO.device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.cbo_sac.SACBO.dtype">
<code class="sig-name descname">dtype</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.cbo_sac.SACBO.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.cbo_sac.SACBO.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], bounds: List[Tuple[float, float]], task_features: List[int], feature_names: List[str], metric_names: List[str], fidelity_features: List[int], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/cbo_sac.html#SACBO.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.cbo_sac.SACBO.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to m outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – A list of m (k_i x d) feature tensors X. Number of rows k_i can
vary from i=1,…,m.</p></li>
<li><p><strong>Ys</strong> – The corresponding list of m (k_i x 1) outcome tensors Y, for
each outcome.</p></li>
<li><p><strong>Yvars</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>bounds</strong> – A list of d (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>task_features</strong> – Columns of X that take integer values and should be
treated as task parameters.</p></li>
<li><p><strong>feature_names</strong> – Names of each column of X.</p></li>
<li><p><strong>metric_names</strong> – Names of each outcome Y in Ys.</p></li>
<li><p><strong>fidelity_features</strong> – Columns of X that should be treated as fidelity
parameters.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.cbo_sac.SACBO.get_and_fit_model">
<code class="sig-name descname">get_and_fit_model</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], task_features: List[int], fidelity_features: List[int], metric_names: List[str], state_dict: Optional[Dict[str, torch.Tensor]] = None, fidelity_model_id: Optional[int] = None, **kwargs: Any</em><span class="sig-paren">)</span> → botorch.models.gpytorch.GPyTorchModel<a class="reference internal" href="_modules/ax/models/torch/cbo_sac.html#SACBO.get_and_fit_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.cbo_sac.SACBO.get_and_fit_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a fitted StructuralAdditiveContextualGP model for each outcome.
:param Xs: X for each outcome.
:param Ys: Y for each outcome.
:param Yvars: Noise variance of Y for each outcome.</p>
<p>Returns: Fitted StructuralAdditiveContextualGP model.</p>
</dd></dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.cbo_sac.generate_model_space_decomposition">
<code class="sig-prename descclassname">ax.models.torch.cbo_sac.</code><code class="sig-name descname">generate_model_space_decomposition</code><span class="sig-paren">(</span><em class="sig-param">decomposition: Dict[str, List[str]], feature_names: List[str]</em><span class="sig-paren">)</span> → Dict[str, List[int]]<a class="reference internal" href="_modules/ax/models/torch/cbo_sac.html#generate_model_space_decomposition"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.cbo_sac.generate_model_space_decomposition" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</div>
<div class="section" id="module-ax.models.torch.frontier_utils">
<span id="ax-models-torch-frontier-utils-module"></span><h3>ax.models.torch.frontier_utils module<a class="headerlink" href="#module-ax.models.torch.frontier_utils" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="ax.models.torch.frontier_utils.get_weighted_mc_objective_and_objective_thresholds">
<code class="sig-prename descclassname">ax.models.torch.frontier_utils.</code><code class="sig-name descname">get_weighted_mc_objective_and_objective_thresholds</code><span class="sig-paren">(</span><em class="sig-param">objective_weights: torch.Tensor</em>, <em class="sig-param">objective_thresholds: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[botorch.acquisition.multi_objective.objective.WeightedMCMultiOutputObjective, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/botorch_moo_defaults.html#get_weighted_mc_objective_and_objective_thresholds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.frontier_utils.get_weighted_mc_objective_and_objective_thresholds" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct weighted objective and apply the weights to objective thresholds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>objective_thresholds</strong> – A tensor containing thresholds forming a reference point
from which to calculate pareto frontier hypervolume. Points that do not
dominate the objective_thresholds contribute nothing to hypervolume.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The objective</p></li>
<li><p>The objective thresholds</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A two-element tuple with the objective and objective thresholds</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.frontier_utils.get_default_frontier_evaluator">
<code class="sig-prename descclassname">ax.models.torch.frontier_utils.</code><code class="sig-name descname">get_default_frontier_evaluator</code><span class="sig-paren">(</span><span class="sig-paren">)</span> → Callable[[ax.models.torch_base.TorchModel, torch.Tensor, Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor], Optional[Tuple[torch.Tensor, torch.Tensor]]], Tuple[torch.Tensor, torch.Tensor]]<a class="reference internal" href="_modules/ax/models/torch/botorch_moo_defaults.html#get_default_frontier_evaluator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.frontier_utils.get_default_frontier_evaluator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</div>
<div class="section" id="module-ax.models.torch.posterior_mean">
<span id="ax-models-torch-posterior-mean-module"></span><h3>ax.models.torch.posterior_mean module<a class="headerlink" href="#module-ax.models.torch.posterior_mean" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="ax.models.torch.posterior_mean.get_PosteriorMean">
<code class="sig-prename descclassname">ax.models.torch.posterior_mean.</code><code class="sig-name descname">get_PosteriorMean</code><span class="sig-paren">(</span><em class="sig-param">model: botorch.models.model.Model</em>, <em class="sig-param">objective_weights: torch.Tensor</em>, <em class="sig-param">outcome_constraints: Optional[Tuple[torch.Tensor</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">X_observed: Optional[torch.Tensor] = None</em>, <em class="sig-param">X_pending: Optional[torch.Tensor] = None</em>, <em class="sig-param">**kwargs: Any</em><span class="sig-paren">)</span> → botorch.acquisition.acquisition.AcquisitionFunction<a class="reference internal" href="_modules/ax/models/torch/posterior_mean.html#get_PosteriorMean"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.posterior_mean.get_PosteriorMean" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a PosteriorMean acquisition function.</p>
<p>Note: If no OutcomeConstraints given, return an analytic acquisition
function. This requires {optimizer_kwargs: {joint_optimization: True}} or an
optimizer that does not assume pending point support.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>X_observed</strong> – A tensor containing points observed for all objective
outcomes and outcomes that appear in the outcome constraints (if
there are any).</p></li>
<li><p><strong>X_pending</strong> – A tensor containing points whose evaluation is pending (i.e.
that have been submitted for evaluation) present for all objective
outcomes and outcomes that appear in the outcome constraints (if
there are any).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The instantiated acquisition function.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>PosteriorMean</p>
</dd>
</dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.rembo">
<span id="ax-models-torch-rembo-module"></span><h3>ax.models.torch.rembo module<a class="headerlink" href="#module-ax.models.torch.rembo" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="ax.models.torch.rembo.REMBO">
<em class="property">class </em><code class="sig-prename descclassname">ax.models.torch.rembo.</code><code class="sig-name descname">REMBO</code><span class="sig-paren">(</span><em class="sig-param">A: torch.Tensor, initial_X_d: torch.Tensor, bounds_d: List[Tuple[float, float]], **kwargs: Any</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ax/models/torch/rembo.html#REMBO"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.rembo.REMBO" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#ax.models.torch.botorch.BotorchModel" title="ax.models.torch.botorch.BotorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ax.models.torch.botorch.BotorchModel</span></code></a></p>
<p>Implements REMBO (Bayesian optimization in a linear subspace).</p>
<p>The (D x d) projection matrix A must be provided, and must be that used for
the initialization. In the original REMBO paper A ~ N(0, 1). Box bounds
in the low-d space must also be provided, which in the REMBO paper should
be [(-sqrt(d), sqrt(d)]^d.</p>
<p>Function evaluations happen in the high-D space, and so the arms on the
experiment will also be tracked in the high-D space. This class maintains
a list of points in the low-d spac that have been launched, so we can match
arms in high-D space back to their low-d point on update.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>A</strong> – (D x d) projection matrix.</p></li>
<li><p><strong>initial_X_d</strong> – Points in low-d space for initial data.</p></li>
<li><p><strong>bounds_d</strong> – Box bounds in the low-d space.</p></li>
<li><p><strong>kwargs</strong> – kwargs for BotorchModel init</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="ax.models.torch.rembo.REMBO.Xs">
<code class="sig-name descname">Xs</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.rembo.REMBO.Xs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.rembo.REMBO.Ys">
<code class="sig-name descname">Ys</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.rembo.REMBO.Ys" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.rembo.REMBO.Yvars">
<code class="sig-name descname">Yvars</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.rembo.REMBO.Yvars" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.rembo.REMBO.best_point">
<code class="sig-name descname">best_point</code><span class="sig-paren">(</span><em class="sig-param">bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Optional[torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/rembo.html#REMBO.best_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.rembo.REMBO.best_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Identify the current best point, satisfying the constraints in the same
format as to gen.</p>
<p>Return None if no such point can be identified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value in the best point.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>d-tensor of the best point.</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.rembo.REMBO.cross_validate">
<code class="sig-name descname">cross_validate</code><span class="sig-paren">(</span><em class="sig-param">Xs_train: List[torch.Tensor], Ys_train: List[torch.Tensor], Yvars_train: List[torch.Tensor], X_test: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/rembo.html#REMBO.cross_validate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.rembo.REMBO.cross_validate" title="Permalink to this definition">¶</a></dt>
<dd><p>Do cross validation with the given training and test sets.</p>
<p>Training set is given in the same format as to fit. Test set is given
in the same format as to predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs_train</strong> – A list of m (k_i x d) feature tensors X. Number of rows
k_i can vary from i=1,…,m.</p></li>
<li><p><strong>Ys_train</strong> – The corresponding list of m (k_i x 1) outcome tensors Y,
for each outcome.</p></li>
<li><p><strong>Yvars_train</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>X_test</strong> – (j x d) tensor of the j points at which to make predictions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) tensor of outcome predictions at X.</p></li>
<li><p>(j x m x m) tensor of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.rembo.REMBO.device">
<code class="sig-name descname">device</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.rembo.REMBO.device" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="attribute">
<dt id="ax.models.torch.rembo.REMBO.dtype">
<code class="sig-name descname">dtype</code><em class="property"> = None</em><a class="headerlink" href="#ax.models.torch.rembo.REMBO.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="method">
<dt id="ax.models.torch.rembo.REMBO.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], bounds: List[Tuple[float, float]], task_features: List[int], feature_names: List[str], metric_names: List[str], fidelity_features: List[int], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/rembo.html#REMBO.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.rembo.REMBO.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to m outcomes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – A list of m (k_i x d) feature tensors X. Number of rows k_i can
vary from i=1,…,m.</p></li>
<li><p><strong>Ys</strong> – The corresponding list of m (k_i x 1) outcome tensors Y, for
each outcome.</p></li>
<li><p><strong>Yvars</strong> – The variances of each entry in Ys, same shape.</p></li>
<li><p><strong>bounds</strong> – A list of d (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>task_features</strong> – Columns of X that take integer values and should be
treated as task parameters.</p></li>
<li><p><strong>feature_names</strong> – Names of each column of X.</p></li>
<li><p><strong>metric_names</strong> – Names of each outcome Y in Ys.</p></li>
<li><p><strong>fidelity_features</strong> – Columns of X that should be treated as fidelity
parameters.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.rembo.REMBO.from_01">
<code class="sig-name descname">from_01</code><span class="sig-paren">(</span><em class="sig-param">X_d01: torch.Tensor</em><span class="sig-paren">)</span> → torch.Tensor<a class="reference internal" href="_modules/ax/models/torch/rembo.html#REMBO.from_01"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.rembo.REMBO.from_01" title="Permalink to this definition">¶</a></dt>
<dd><p>Map points from [0, 1] to bounds_d.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X_d01</strong> – Tensor in [0, 1]</p>
</dd>
</dl>
<p>Returns: Tensor in bounds_d.</p>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.rembo.REMBO.gen">
<code class="sig-name descname">gen</code><span class="sig-paren">(</span><em class="sig-param">n: int, bounds: List[Tuple[float, float]], objective_weights: torch.Tensor, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, linear_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, fixed_features: Optional[Dict[int, float]] = None, pending_observations: Optional[List[torch.Tensor]] = None, model_gen_options: Optional[Dict[str, Union[int, float, str, botorch.acquisition.acquisition.AcquisitionFunction, Dict[str, Any]]]] = None, rounding_func: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, target_fidelities: Optional[Dict[int, float]] = None</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor, Dict[str, Any], Optional[List[Optional[Dict[str, Any]]]]]<a class="reference internal" href="_modules/ax/models/torch/rembo.html#REMBO.gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.rembo.REMBO.gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate new candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> – Number of candidates to generate.</p></li>
<li><p><strong>bounds</strong> – A list of (lower, upper) tuples for each column of X.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b.</p></li>
<li><p><strong>linear_constraints</strong> – A tuple of (A, b). For k linear constraints on
d-dimensional x, A is (k x d) and b is (k x 1) such that
A x &lt;= b.</p></li>
<li><p><strong>fixed_features</strong> – A map {feature_index: value} for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>pending_observations</strong> – A list of m (k_i x d) feature tensors X
for m outcomes and k_i pending observations for outcome i.</p></li>
<li><p><strong>model_gen_options</strong> – A config dictionary that can contain
model-specific options.</p></li>
<li><p><strong>rounding_func</strong> – A function that rounds an optimization result
appropriately (i.e., according to <cite>round-trip</cite> transformations).</p></li>
<li><p><strong>target_fidelities</strong> – A map {feature_index: value} of fidelity feature
column indices to their respective target fidelities. Used for
multi-fidelity optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>4-element tuple containing</p>
<ul class="simple">
<li><p>(n x d) tensor of generated points.</p></li>
<li><p>n-tensor of weights for each point.</p></li>
<li><p>Generation metadata</p></li>
<li><dl class="simple">
<dt>Dictionary of model-specific metadata for the given</dt><dd><p>generation candidates</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.rembo.REMBO.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/rembo.html#REMBO.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.rembo.REMBO.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – (j x d) tensor of the j points at which to make predictions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>2-element tuple containing</p>
<ul class="simple">
<li><p>(j x m) tensor of outcome predictions at X.</p></li>
<li><p>(j x m x m) tensor of predictive covariances at X.
cov[j, m1, m2] is Cov[m1@j, m2@j].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.rembo.REMBO.project_down">
<code class="sig-name descname">project_down</code><span class="sig-paren">(</span><em class="sig-param">X_D: torch.Tensor</em><span class="sig-paren">)</span> → torch.Tensor<a class="reference internal" href="_modules/ax/models/torch/rembo.html#REMBO.project_down"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.rembo.REMBO.project_down" title="Permalink to this definition">¶</a></dt>
<dd><p>Map points in the high-D space to the low-d space by looking them
up in self.X_d.</p>
<p>We assume that X_D = self.project_up(self.X_d), except possibly with
rows shuffled. If a value in X_d cannot be found for each row in X_D,
an error will be raised.</p>
<p>This is quite fast relative to model fitting, so we do it in O(n^2)
time and don’t worry about it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X_D</strong> – Tensor in high-D space.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor in low-d space.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>X_d</p>
</dd>
</dl>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.rembo.REMBO.project_up">
<code class="sig-name descname">project_up</code><span class="sig-paren">(</span><em class="sig-param">X: torch.Tensor</em><span class="sig-paren">)</span> → torch.Tensor<a class="reference internal" href="_modules/ax/models/torch/rembo.html#REMBO.project_up"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.rembo.REMBO.project_up" title="Permalink to this definition">¶</a></dt>
<dd><p>Project to high-dimensional space.</p>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.rembo.REMBO.to_01">
<code class="sig-name descname">to_01</code><span class="sig-paren">(</span><em class="sig-param">X_d: torch.Tensor</em><span class="sig-paren">)</span> → torch.Tensor<a class="reference internal" href="_modules/ax/models/torch/rembo.html#REMBO.to_01"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.rembo.REMBO.to_01" title="Permalink to this definition">¶</a></dt>
<dd><p>Map points from bounds_d to [0, 1].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X_d</strong> – Tensor in bounds_d</p>
</dd>
</dl>
<p>Returns: Tensor in [0, 1].</p>
</dd></dl>
<dl class="method">
<dt id="ax.models.torch.rembo.REMBO.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">Xs: List[torch.Tensor], Ys: List[torch.Tensor], Yvars: List[torch.Tensor], candidate_metadata: Optional[List[List[Optional[Dict[str, Any]]]]] = None</em><span class="sig-paren">)</span> → None<a class="reference internal" href="_modules/ax/models/torch/rembo.html#REMBO.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.rembo.REMBO.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the model.</p>
<p>Updating the model requires both existing and additional data.
The data passed into this method will become the new training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Xs</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>Ys</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>Yvars</strong> – Existing + additional data for the model,
in the same format as for <cite>fit</cite>.</p></li>
<li><p><strong>candidate_metadata</strong> – Model-produced metadata for candidates, in
the order corresponding to the Xs.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="module-ax.models.torch.utils">
<span id="ax-models-torch-utils-module"></span><h3>ax.models.torch.utils module<a class="headerlink" href="#module-ax.models.torch.utils" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="ax.models.torch.utils.get_botorch_objective">
<code class="sig-prename descclassname">ax.models.torch.utils.</code><code class="sig-name descname">get_botorch_objective</code><span class="sig-paren">(</span><em class="sig-param">model: botorch.models.model.Model</em>, <em class="sig-param">objective_weights: torch.Tensor</em>, <em class="sig-param">use_scalarized_objective: bool = True</em>, <em class="sig-param">outcome_constraints: Optional[Tuple[torch.Tensor</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">X_observed: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> → botorch.acquisition.objective.AcquisitionObjective<a class="reference internal" href="_modules/ax/models/torch/utils.html#get_botorch_objective"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.utils.get_botorch_objective" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a BoTorch <cite>AcquisitionObjective</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – A BoTorch Model</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>use_scalarized_objective</strong> – A boolean parameter that defaults to True,
specifying whether ScalarizedObjective should be used.
NOTE: when using outcome_constraints, use_scalarized_objective
will be ignored.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>X_observed</strong> – Observed points that are feasible and appear in the
objective or the constraints. None if there are no such points.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><cite>ScalarizedObjective</cite>, <cite>LinearMCOObjective</cite>, <cite>ConstrainedMCObjective</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>A BoTorch <cite>AcquisitionObjective</cite> object. It will be one of</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.utils.get_out_of_sample_best_point_acqf">
<code class="sig-prename descclassname">ax.models.torch.utils.</code><code class="sig-name descname">get_out_of_sample_best_point_acqf</code><span class="sig-paren">(</span><em class="sig-param">model: botorch.models.model.Model, Xs: List[torch.Tensor], X_observed: torch.Tensor, objective_weights: torch.Tensor, mc_samples: int = 512, fixed_features: Optional[Dict[int, float]] = None, fidelity_features: Optional[List[int]] = None, target_fidelities: Optional[Dict[int, float]] = None, outcome_constraints: Optional[Tuple[torch.Tensor, torch.Tensor]] = None, seed_inner: Optional[int] = None, qmc: bool = True, **kwargs: Any</em><span class="sig-paren">)</span> → Tuple[botorch.acquisition.acquisition.AcquisitionFunction, Optional[List[int]]]<a class="reference internal" href="_modules/ax/models/torch/utils.html#get_out_of_sample_best_point_acqf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.utils.get_out_of_sample_best_point_acqf" title="Permalink to this definition">¶</a></dt>
<dd><p>Picks an appropriate acquisition function to find the best
out-of-sample (predicted by the given surrogate model) point
and instantiates it.</p>
<p>NOTE: Typically the appropriate function is the posterior mean,
but can differ to account for fidelities etc.</p>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.utils.is_noiseless">
<code class="sig-prename descclassname">ax.models.torch.utils.</code><code class="sig-name descname">is_noiseless</code><span class="sig-paren">(</span><em class="sig-param">model: botorch.models.model.Model</em><span class="sig-paren">)</span> → bool<a class="reference internal" href="_modules/ax/models/torch/utils.html#is_noiseless"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.utils.is_noiseless" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if a given (single-task) botorch model is noiseless</p>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.utils.normalize_indices">
<code class="sig-prename descclassname">ax.models.torch.utils.</code><code class="sig-name descname">normalize_indices</code><span class="sig-paren">(</span><em class="sig-param">indices: List[int], d: int</em><span class="sig-paren">)</span> → List[int]<a class="reference internal" href="_modules/ax/models/torch/utils.html#normalize_indices"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.utils.normalize_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalize a list of indices to ensure that they are positive.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> – A list of indices (may contain negative indices for indexing
“from the back”).</p></li>
<li><p><strong>d</strong> – The dimension of the tensor to index.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A normalized list of indices such that each index is between <cite>0</cite> and <cite>d-1</cite>.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.utils.pick_best_out_of_sample_point_acqf_class">
<code class="sig-prename descclassname">ax.models.torch.utils.</code><code class="sig-name descname">pick_best_out_of_sample_point_acqf_class</code><span class="sig-paren">(</span><em class="sig-param">outcome_constraints: Optional[Tuple[torch.Tensor</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">mc_samples: int = 512</em>, <em class="sig-param">qmc: bool = True</em>, <em class="sig-param">seed_inner: Optional[int] = None</em><span class="sig-paren">)</span> → Tuple[Type[botorch.acquisition.acquisition.AcquisitionFunction], Dict[str, Any]]<a class="reference internal" href="_modules/ax/models/torch/utils.html#pick_best_out_of_sample_point_acqf_class"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.utils.pick_best_out_of_sample_point_acqf_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="function">
<dt id="ax.models.torch.utils.predict_from_model">
<code class="sig-prename descclassname">ax.models.torch.utils.</code><code class="sig-name descname">predict_from_model</code><span class="sig-paren">(</span><em class="sig-param">model: botorch.models.model.Model</em>, <em class="sig-param">X: torch.Tensor</em><span class="sig-paren">)</span> → Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="_modules/ax/models/torch/utils.html#predict_from_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.utils.predict_from_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts outcomes given a model and input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – A botorch Model.</p></li>
<li><p><strong>X</strong> – A <cite>n x d</cite> tensor of input parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The predicted posterior mean as an <cite>n x o</cite>-dim tensor.
Tensor: The predicted posterior covariance as a <cite>n x o x o</cite>-dim tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.utils.randomize_objective_weights">
<code class="sig-prename descclassname">ax.models.torch.utils.</code><code class="sig-name descname">randomize_objective_weights</code><span class="sig-paren">(</span><em class="sig-param">objective_weights: torch.Tensor</em>, <em class="sig-param">**acquisition_function_kwargs: Any</em><span class="sig-paren">)</span> → torch.Tensor<a class="reference internal" href="_modules/ax/models/torch/utils.html#randomize_objective_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.utils.randomize_objective_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a random weighting based on acquisition function settings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>objective_weights</strong> – Base weights to multiply by random values..</p></li>
<li><p><strong>**acquisition_function_kwargs</strong> – Kwargs containing weight generation algorithm
options.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A normalized list of indices such that each index is between <cite>0</cite> and <cite>d-1</cite>.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.utils.subset_model">
<code class="sig-prename descclassname">ax.models.torch.utils.</code><code class="sig-name descname">subset_model</code><span class="sig-paren">(</span><em class="sig-param">model: botorch.models.model.Model</em>, <em class="sig-param">objective_weights: torch.Tensor</em>, <em class="sig-param">outcome_constraints: Optional[Tuple[torch.Tensor</em>, <em class="sig-param">torch.Tensor]] = None</em>, <em class="sig-param">Ys: Optional[List[torch.Tensor]] = None</em><span class="sig-paren">)</span> → Tuple[botorch.models.model.Model, torch.Tensor, Optional[Tuple[torch.Tensor, torch.Tensor]], Optional[List[torch.Tensor]]]<a class="reference internal" href="_modules/ax/models/torch/utils.html#subset_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.utils.subset_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset a botorch model to the outputs used in the optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – A BoTorch Model. If the model does not implement the
<cite>subset_outputs</cite> method, this function is a null-op and returns the
input arguments.</p></li>
<li><p><strong>objective_weights</strong> – The objective is to maximize a weighted sum of
the columns of f(x). These are the weights.</p></li>
<li><p><strong>outcome_constraints</strong> – A tuple of (A, b). For k outcome constraints
and m outputs at f(x), A is (k x m) and b is (k x 1) such that
A f(x) &lt;= b. (Not used by single task models)</p></li>
<li><p><strong>Ys</strong> – The corresponding list of m (k_i x 1) outcome tensors Y, for
each outcome.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A three-tuple of model, objective_weights, and outcome_constraints, all
subset to only those outputs that appear in either the objective weights
or the outcome constraints.</p>
</dd>
</dl>
</dd></dl>
<dl class="function">
<dt id="ax.models.torch.utils.tensor_callable_to_array_callable">
<code class="sig-prename descclassname">ax.models.torch.utils.</code><code class="sig-name descname">tensor_callable_to_array_callable</code><span class="sig-paren">(</span><em class="sig-param">tensor_func: Callable[[torch.Tensor], torch.Tensor], device: torch.device</em><span class="sig-paren">)</span> → Callable[[numpy.ndarray], numpy.ndarray]<a class="reference internal" href="_modules/ax/models/torch/utils.html#tensor_callable_to_array_callable"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ax.models.torch.utils.tensor_callable_to_array_callable" title="Permalink to this definition">¶</a></dt>
<dd><p>“transfer a tensor callable to an array callable</p>
</dd></dl>
</div>
</div>
</div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Ax</a></h1>
<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="ax.html">ax</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">ax.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="core.html">ax.core</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">ax.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">ax.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="modelbridge.html">ax.modelbridge</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">ax.models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#base-models">Base Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#discrete-models">Discrete Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#numpy-models">NumPy Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#random-models">Random Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#torch-models">Torch Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="plot.html">ax.plot</a></li>
<li class="toctree-l1"><a class="reference internal" href="runners.html">ax.runners</a></li>
<li class="toctree-l1"><a class="reference internal" href="service.html">ax.service</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">ax.storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">ax.utils</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="index.html">Documentation overview</a><ul>
<li>Previous: <a href="modelbridge.html" title="previous chapter">ax.modelbridge</a></li>
<li>Next: <a href="plot.html" title="next chapter">ax.plot</a></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="search.html" class="search" method="get">
<input aria-labelledby="searchlabel" name="q" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div></section><a href="https://code.facebook.com/projects/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/versions/latest/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright">Copyright © 2020 Facebook Inc.</section></footer></div></body></html>